{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380874e2",
   "metadata": {},
   "source": [
    "# Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b9174e-9dbf-46d2-a07b-d4ea61c084d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96164230",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 101000\n",
    "on_remote = False\n",
    "\n",
    "if on_remote:\n",
    "    SUBS_data_filename = Path(f'/nobackup/smhid20/users/sm_maran/dpr_data/simulations/QG_samples_SUBS_{iterations}.npy')\n",
    "else:\n",
    "    SUBS_data_filename = Path(f'C:/Users/svart/Desktop/MEX/data/QG_samples_SUBS_101000.npy')\n",
    "\n",
    "X_subs = np.load(SUBS_data_filename).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d0fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(p_train, k, spinup, spacing):\n",
    "    N = iterations + 1\n",
    "    n_train = int(np.round(p_train * (N - spinup)))\n",
    "    n_val = int(np.round((1 - p_train)/2 * (N - spinup)))\n",
    "\n",
    "    start, stop = spinup, spinup + n_train\n",
    "    fit_x, fit_y = slice(start, stop - k), slice(start + k, stop)\n",
    "\n",
    "    start, stop = stop, stop + n_val\n",
    "    val_x, val_y = slice(start, stop - k), slice(start + k, stop)\n",
    "\n",
    "    start, stop = stop, N\n",
    "    prd_x, prd_y = slice(start, stop - k), slice(start + k, stop)\n",
    "\n",
    "    # Data\n",
    "    X_train, Y_train =  X_subs[fit_x], X_subs[fit_y]\n",
    "    X_val, Y_val =      X_subs[val_x], X_subs[val_y]\n",
    "    X_test, Y_test =    X_subs[prd_x], X_subs[prd_y]\n",
    "        \n",
    "    return X_train[::spacing], Y_train[::spacing], X_val[::spacing], Y_val[::spacing], X_test[::spacing], Y_test[::spacing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f45451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 150\n",
    "spinup = 1001\n",
    "spacing = 10\n",
    "p_train = 0.8\n",
    "\n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = generate_data(p_train, k, spinup, spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee27a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_data = X_train.mean()\n",
    "std_data = X_train.std()\n",
    "\n",
    "def normalize_X(X):\n",
    "    return (X - mean_data)/std_data\n",
    "\n",
    "X_train_normalized = normalize_X(X_train)\n",
    "Y_train_normalized = normalize_X(Y_train)\n",
    "\n",
    "X_val_normalized = normalize_X(X_val)\n",
    "X_test_normalized = normalize_X(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e75c74c",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a4e989",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA()\n",
    "X_transformed_PCA = pca.fit_transform(X_train_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reconstruct data using first l components\n",
    "def reconstruct_data(transformed_data, pca, l):\n",
    "    return np.dot(transformed_data[:, :l], pca.components_[:l, :]) + pca.mean_\n",
    "\n",
    "def reconstruction_error(original_data, reconstructed_data):\n",
    "    return np.mean(np.square(original_data - reconstructed_data))\n",
    "\n",
    "def plot_image(x):\n",
    "    x = x.reshape((65,65))\n",
    "    plt.imshow(x)\n",
    "\n",
    "def get_encoded(x, l):\n",
    "    return x[:l]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of l values (number of components)\n",
    "l_values = [int(l) for l in np.logspace(1, np.log10(4225), 10)]\n",
    "\n",
    "errors = []\n",
    "\n",
    "for l in l_values:\n",
    "    reconstructed_data = reconstruct_data(X_transformed_PCA, pca, l)\n",
    "    error = reconstruction_error(X_train_normalized, reconstructed_data)\n",
    "    errors.append(error)\n",
    "\n",
    "# Plotting the reconstruction errors\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.loglog(l_values, errors, marker='o')\n",
    "plt.grid(True,'both')\n",
    "plt.xlabel('Number of components (l)')\n",
    "plt.ylabel('Reconstruction error')\n",
    "plt.title('Reconstruction error as a function of l')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb80af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 100\n",
    "X_PCA = reconstruct_data(X_transformed_PCA, pca, l)\n",
    "error = reconstruction_error(X_train_normalized, X_PCA)\n",
    "print(error)\n",
    "plot_image(X_PCA[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac5f724",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c218d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dbfdfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "409e1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_normalized, dtype=torch.float32).to(device)  # Convert to tensor\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor[:-1], X_train_tensor[1:])\n",
    "batch_size = 32  # You can choose a batch size that fits your needs\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9972484",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33dccf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size[0]),\n",
    "            #nn.LeakyReLU(inplace=True, negative_slope=0.5),\n",
    "            #nn.Linear(hidden_size[0], hidden_size[1]),\n",
    "            #nn.ReLU(True),\n",
    "            #nn.Linear(hidden_size[1], hidden_size[2]),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            #nn.Linear(hidden_size[2], hidden_size[1]),\n",
    "            #nn.ReLU(True),\n",
    "            #nn.Linear(hidden_size[1], hidden_size[0]),\n",
    "            #nn.LeakyReLU(inplace=True, negative_slope=0.5),\n",
    "            nn.Linear(hidden_size[0], input_size),\n",
    "        )\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "\n",
    "    @staticmethod  \n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f8bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = False\n",
    "if not saved_model:\n",
    "    linear_model = Autoencoder(input_size=4225, hidden_size=(100,))  # Example sizes\n",
    "    linear_model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(linear_model.parameters(), lr=1e-3)\n",
    "    \n",
    "    loss_values_linear = []\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss=0\n",
    "    for data in train_loader:\n",
    "        img,_ = data  # Assuming the dataset returns a tuple (image, label)\n",
    "        output = linear_model(img)\n",
    "        loss = criterion(output, img)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    total_loss = total_loss / len(train_loader)\n",
    "    loss_values_linear.append(total_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {total_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.loglog(loss_values_linear, color='blue')\n",
    "plt.title('Loss as a Function of Epochs\\nLinear model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b7055",
   "metadata": {},
   "source": [
    "### Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f721116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.image_size = 65\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Unflatten(1,(1,self.image_size, self.image_size)),\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(in_features=16*4225, out_features=100),\n",
    "            )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=100, out_features=16*4225),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1,(16, self.image_size, self.image_size)),\n",
    "            nn.Conv2d(in_channels=16, out_channels=1, kernel_size=3, padding=1),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            )\n",
    "        \n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            torch.nn.init.constant_(m.weight, 1)\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c43956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Average Loss: 4.7506\n",
      "Epoch [2/200], Average Loss: 0.7446\n",
      "Epoch [3/200], Average Loss: 0.5409\n",
      "Epoch [4/200], Average Loss: 0.4358\n",
      "Epoch [5/200], Average Loss: 0.3756\n",
      "Epoch [6/200], Average Loss: 0.3456\n",
      "Epoch [7/200], Average Loss: 0.3240\n",
      "Epoch [8/200], Average Loss: 0.3045\n",
      "Epoch [9/200], Average Loss: 0.2928\n",
      "Epoch [10/200], Average Loss: 0.2899\n",
      "Epoch [11/200], Average Loss: 0.2855\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m output \u001b[38;5;241m=\u001b[39m conv_model(img)\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, img)\n\u001b[1;32m---> 21\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Regular MSE loss\n",
    "\n",
    "saved_model = True\n",
    "if not saved_model:\n",
    "    conv_model = ConvAutoencoder()\n",
    "    conv_model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(conv_model.parameters(), lr=1e-3, weight_decay=0.1)\n",
    "\n",
    "    loss_values_conv = []\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss=0\n",
    "    for data in train_loader:\n",
    "        img,_ = data  # Assuming the dataset returns a tuple (image, label)\n",
    "        output = conv_model(img)\n",
    "        loss = criterion(output, img)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    total_loss = total_loss / len(train_loader)\n",
    "    loss_values_conv.append(total_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {total_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a89b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, conv_model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.loglog(loss_values_conv, color='blue')\n",
    "plt.title('Loss as a Function of Epochs\\nConv model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e2b7b",
   "metadata": {},
   "source": [
    "## Regularized Loss CAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1459f0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 5.8560, Reconstruction: 2.8750, Temporal: 0.1060\n",
      "Epoch [2/10], Average Loss: 1.7105, Reconstruction: 0.8400, Temporal: 0.0305\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 36\u001b[0m\n\u001b[0;32m     31\u001b[0m loss_reconstruction \u001b[38;5;241m=\u001b[39m criterion(current_reconstruction, current_state) \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     32\u001b[0m                       criterion(next_reconstruction, next_state)\n\u001b[0;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_reconstruction \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m loss_temporal\n\u001b[1;32m---> 36\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m total_loss_reconstruction \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_reconstruction\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     38\u001b[0m total_loss_temporal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_temporal\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# More interesting loss\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "alpha = 1\n",
    "saved_model = False\n",
    "if not saved_model:\n",
    "    conv_model = ConvAutoencoder()\n",
    "    conv_model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(conv_model.parameters(), lr=1e-3)\n",
    "\n",
    "    loss_values_conv = []\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss_reconstruction = 0\n",
    "    total_loss_temporal = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for current_state, next_state in train_loader:\n",
    "\n",
    "        current_latent = conv_model.encoder(current_state)\n",
    "        next_latent = conv_model.encoder(next_state)\n",
    "        \n",
    "        loss_temporal = criterion(current_latent, next_latent)\n",
    "\n",
    "        current_reconstruction = conv_model.decoder(current_latent)\n",
    "        next_reconstruction = conv_model.decoder(next_latent)\n",
    "        \n",
    "        loss_reconstruction = criterion(current_reconstruction, current_state) + \\\n",
    "                              criterion(next_reconstruction, next_state)\n",
    "        \n",
    "        loss = loss_reconstruction + alpha * loss_temporal\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_loss_reconstruction += loss_reconstruction.item()\n",
    "        total_loss_temporal += loss_temporal.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    total_loss_reconstruction /= 2 * len(train_loader)\n",
    "    total_loss_temporal /= len(train_loader)\n",
    "    total_loss /= len(train_loader)\n",
    "\n",
    "    loss_values_conv.append([total_loss, total_loss_reconstruction, total_loss_temporal])\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {total_loss:.4f}, Reconstruction: {total_loss_reconstruction:.4f}, Temporal: {total_loss_temporal:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba9d25",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_normalized = normalize_X(X_val)\n",
    "X_val_tensor = torch.tensor(X_val_normalized, dtype=torch.float32).to(device)  # Convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da2e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_model\n",
    "\n",
    "l = 100\n",
    "X_PCA_test = reconstruct_data(pca.transform(X_val_normalized), pca, l)\n",
    "X_AE_test = model(X_val_tensor).cpu().detach().numpy()\n",
    "\n",
    "error_pca = reconstruction_error(X_val_normalized, X_PCA_test)\n",
    "error_ae = reconstruction_error(X_val_normalized, X_AE_test)\n",
    "print(error_pca, error_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "cmap = 'viridis'\n",
    "\n",
    "random_index = np.random.randint(len(X_test))\n",
    "image_shape = (65, 65)  # Replace with the actual shape of your images\n",
    "\n",
    "img_train = X_val_normalized[random_index].reshape(image_shape)\n",
    "\n",
    "img_pca = X_PCA_test[random_index].reshape(image_shape)\n",
    "\n",
    "X_AE = model(X_val_tensor[random_index].unsqueeze(0)).cpu().detach().numpy()\n",
    "img_ae =  X_AE.reshape(image_shape)\n",
    "\n",
    "X_enc = model.encoder(X_val_tensor[random_index].unsqueeze(0)).cpu().detach().numpy()\n",
    "img_enc =  X_enc.reshape((10,10))\n",
    "\n",
    "#img_enc = get_encoded(X_PCA_test[random_index], l).reshape((10,10))\n",
    "\n",
    "\n",
    "vmin = min(img_pca.min(), img_train.min(), img_ae.min())\n",
    "vmax = max(img_pca.max(), img_train.max(), img_ae.max())\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 7))\n",
    "axes[0,0].imshow(img_train, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "axes[0,0].set_title('Original Image')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "axes[0,1].imshow(img_pca, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "axes[0,1].set_title(f'PCA Image')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(img_ae, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "axes[0,2].set_title(f'Autoencoder Image')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[1,0].plot(img_enc.flatten())\n",
    "axes[1,0].set_title('Encoded Image')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "vmin_diff = min((img_pca-img_train).min(), (img_ae-img_train).min())\n",
    "vmax_diff = max((img_pca-img_train).max(), (img_ae-img_train).max())\n",
    "\n",
    "axes[1,1].imshow(img_pca- img_train, cmap=cmap, vmin=vmin_diff, vmax=vmax_diff)\n",
    "er_PCA = np.round(reconstruction_error(img_train, img_pca),4)\n",
    "axes[1,1].set_title(f'{str(er_PCA)}')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(img_ae-img_train, cmap=cmap, vmin=vmin_diff, vmax=vmax_diff)\n",
    "er_AE = np.round(reconstruction_error(img_train, img_ae), 4)\n",
    "axes[1,2].set_title(f'{str(er_AE)}')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac1c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "cmap = 'viridis'\n",
    "random_index = np.random.randint(len(X_test))\n",
    "l=100\n",
    "image_shape = (65, 65)  # Replace with the actual shape of your images\n",
    "latent_shape = (10, 10)  # Replace with the actual shape of your images\n",
    "\n",
    "img_train = X_val_normalized[random_index].reshape(image_shape)\n",
    "img_train_next = X_val_normalized[random_index+1].reshape(image_shape)\n",
    "\n",
    "img_pca = X_PCA_test[random_index].reshape(image_shape)\n",
    "img_pca_next = X_PCA_test[random_index+1].reshape(image_shape)\n",
    "\n",
    "img_ae = model(X_val_tensor[random_index].unsqueeze(0)).cpu().detach().numpy().reshape(image_shape)\n",
    "img_ae_next = model(X_val_tensor[random_index+1].unsqueeze(0)).cpu().detach().numpy().reshape(image_shape)\n",
    "\n",
    "img_enc = get_encoded(X_PCA_test[random_index], l)\n",
    "img_enc_next = get_encoded(X_PCA_test[random_index+1],l)\n",
    "\n",
    "vmin = min(img_pca.min(), img_train.min(), img_train_next.min(), img_pca_next.min())\n",
    "vmax = max(img_pca.max(), img_train.max(), img_train_next.max(), img_pca_next.max())\n",
    "\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12))\n",
    "\n",
    "# Train\n",
    "axes[0,0].imshow(img_train, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "axes[0,0].set_title('Original Image')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "axes[1,0].imshow(img_train_next, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "gradient_x, gradient_y = np.gradient(img_train_next - img_train)\n",
    "X, Y = np.meshgrid(np.arange(gradient_x.shape[1]), np.arange(gradient_y.shape[0]))\n",
    "axes[2,0].imshow(img_train_next - img_train, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "axes[2,0].quiver(X, Y, gradient_x, gradient_y)\n",
    "axes[2,0].axis('off')\n",
    "\n",
    "\n",
    "# PCA\n",
    "axes[0,1].imshow(img_pca, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "axes[0,1].set_title(f'PCA Image')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[1,1].imshow(img_pca_next, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "# Compute the difference\n",
    "difference = img_pca_next - img_pca\n",
    "gradient_x, gradient_y = np.gradient(difference)\n",
    "axes[2,1].imshow(img_pca_next - img_pca, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "axes[2,1].quiver(X, Y, gradient_x, gradient_y)\n",
    "axes[2,1].axis('off')\n",
    "\n",
    "# AE\n",
    "axes[0,2].imshow(img_ae, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "axes[0,2].set_title(f'AE Image')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[1,2].imshow(img_ae_next, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "# Compute the difference\n",
    "difference = img_ae_next - img_ae\n",
    "gradient_x, gradient_y = np.gradient(difference)\n",
    "axes[2,2].imshow(img_ae_next - img_ae, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "axes[2,2].quiver(X, Y, gradient_x, gradient_y)\n",
    "axes[2,2].axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba393be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "cmap = 'viridis'\n",
    "random_index = np.random.randint(len(X_test))\n",
    "another_random_index = random_index + 1 #np.random.randint(len(X_test))\n",
    "\n",
    "l=100\n",
    "image_shape = (65, 65)  # Replace with the actual shape of your images\n",
    "latent_shape = (10, 10)  # Replace with the actual shape of your images\n",
    "\n",
    "img_enc_pca = get_encoded(X_PCA_test[random_index], l)\n",
    "img_enc_pca_next = get_encoded(X_PCA_test[another_random_index],l)\n",
    "\n",
    "vmin_pca = min(img_enc_pca.min(), img_enc_pca_next.min())\n",
    "vmax_pca = max(img_enc_pca.max(), img_enc_pca_next.max())\n",
    "\n",
    "err_pca = str(np.round(np.mean(((img_enc_pca_next - img_enc_pca)/(vmax_pca - vmin_pca))**2),4))\n",
    "\n",
    "\n",
    "img_enc_ae = model.encoder(X_val_tensor[random_index].unsqueeze(0)).cpu().detach().numpy().flatten()\n",
    "img_enc_ae_next = model.encoder(X_val_tensor[another_random_index].unsqueeze(0)).cpu().detach().numpy().flatten()\n",
    "\n",
    "vmin_ae = min(img_enc_ae.min(), img_enc_ae_next.min())\n",
    "vmax_ae = max(img_enc_ae.max(), img_enc_ae_next.max())\n",
    "\n",
    "err_ae = str(np.round(np.mean(((img_enc_ae_next - img_enc_ae)/(vmax_ae - vmin_ae))**2),4))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,2, figsize=(12, 12))\n",
    "\n",
    "axes[0,0].plot(img_enc_pca)\n",
    "axes[0,0].set_title(f'PCA\\n{err_pca}')\n",
    "axes[0,0].set_ylim([vmin_pca, vmax_pca])\n",
    "axes[1,0].plot(img_enc_pca_next)\n",
    "axes[1,0].set_ylim([vmin_pca, vmax_pca])\n",
    "axes[2,0].plot(img_enc_pca_next - img_enc_pca)\n",
    "\n",
    "axes[0,1].plot(img_enc_ae)\n",
    "axes[0,1].set_title(f'AE\\n{err_ae}')\n",
    "axes[0,1].set_ylim([vmin_ae, vmax_ae])\n",
    "axes[1,1].plot(img_enc_ae_next)\n",
    "axes[1,1].set_ylim([vmin_ae, vmax_ae])\n",
    "axes[2,1].plot(img_enc_ae_next - img_enc_ae)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
