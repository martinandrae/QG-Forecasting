{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for the analysis.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import csv\n",
    "import math\n",
    "import json\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from tqdm import tqdm\n",
    "import pandas as pd, datetime\n",
    "import time\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from utils import *\n",
    "from autoencoder_networks import *\n",
    "from diffusion_networks import *\n",
    "from sampler import *\n",
    "from calculations import *\n",
    "from loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cmap = plt.cm.get_cmap('viridis',30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Loading**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QG Dataset\n",
    "\n",
    "batch_size = 64 # 256 Largest possible batch size that fits on the GPU w.f32\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "mean_data = 0.003394413273781538\n",
    "std_data = 9.174626350402832\n",
    "norm_factors = (mean_data, std_data)\n",
    "\n",
    "iterations = 2101000\n",
    "spinup = 1001\n",
    "spacing = 1\n",
    "p_train = 0.8\n",
    "\n",
    "n_samples = iterations+1\n",
    "n_train = int(np.round(p_train * (n_samples - spinup)))  # Number of training samples\n",
    "n_val = int(np.round((1 - p_train) / 2 * (n_samples - spinup)))  # Number of validation samples\n",
    "sample_counts = (n_samples, n_train, n_val)\n",
    "\n",
    "on_remote = True\n",
    "fname= f'QG_samples_SUBS_{iterations}.npy'\n",
    "subd = 'C:/Users/svart/Desktop/MEX/data/'\n",
    "if on_remote:\n",
    "    #subd = '/nobackup/smhid20/users/sm_maran/dpr_data/simulations'\n",
    "    subd = '/proj/berzelius-2022-164/users/sm_maran/data/qg'\n",
    "dataset_path = Path(f'{subd}/{fname}')\n",
    "\n",
    "\n",
    "grid_dimensions = (65, 65)\n",
    "max_lead_time = 150\n",
    "\n",
    "QG_kwargs = {\n",
    "            'dataset_path':     dataset_path,\n",
    "            'sample_counts':    sample_counts,\n",
    "            'grid_dimensions':  grid_dimensions,\n",
    "            'max_lead_time':    max_lead_time,\n",
    "            'norm_factors':     norm_factors,\n",
    "            'device':           device,\n",
    "            'spinup':           spinup,\n",
    "            'spacing':          spacing,\n",
    "            'dtype':            'float32'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Way to load a dataset with a specific lead time\n",
    "train_dataset = QGDataset(lead_time=100, dataset_mode='train', **QG_kwargs)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Way to load a dataset with a specific lead time\n",
    "val_dataset = QGDataset(lead_time=150, dataset_mode='val', **QG_kwargs)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Way to load a dataset with a specific lead time\n",
    "test_dataset = QGDataset(lead_time=150, dataset_mode='test', **QG_kwargs)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Way to load a dataset with lead time following a distribution given by update_k_per_batch\n",
    "update_k_per_batch = get_uniform_k_dist_fn(kmin=1, kmax=150, d=1)\n",
    "\n",
    "train_time_dataset = QGDataset(lead_time=max_lead_time, dataset_mode='train', **QG_kwargs)\n",
    "train_batch_sampler = DynamicKBatchSampler(train_time_dataset, batch_size=batch_size, drop_last=True, k_update_callback=update_k_per_batch, shuffle=True)\n",
    "train_time_loader = DataLoader(train_time_dataset, batch_sampler=train_batch_sampler)\n",
    "\n",
    "# Way to load a single trajectory. Only uses 1 batch.\n",
    "t_kmin = 50\n",
    "t_kmax = 150\n",
    "t_d = 50\n",
    "k_series = t_kmin + t_d * np.arange(0, 1 + (t_kmax-t_kmin)//t_d)\n",
    "val_time_series_dataset = QGDataset(lead_time=k_series, dataset_mode='val', **QG_kwargs)\n",
    "val_time_series_loader = DataLoader(val_time_series_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed_std = torch.tensor(np.loadtxt('stds/QG_stds.txt',delimiter=' ')[:,1], dtype=torch.float32).to(device)\n",
    "def residual_scaling(x):\n",
    "    return precomputed_std[x.to(dtype=int)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QG NWP comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical model\n",
    "n_val = 210000\n",
    "\n",
    "#nwp_data_path = Path(f'/nobackup/smhid20/users/sm_maran/dpr_data/simulations/QG_samples_LRES_{iterations}_n_{n_val}_k_{k}.npy') if on_remote else Path(f'C:/Users/svart/Desktop/MEX/data/QG_samples_LRES_{iterations}_n_{n_val}_k_{k}.npy')\n",
    "nwp_data_path = Path(f'C:/Users/svart/Desktop/MEX/data/QG_samples_LRES_Test_{iterations}_n_{n_val}_k_{k}.npy')\n",
    "\n",
    "nwp_dataset = NWPDataset(nwp_data_path, n_val=n_val, spacing=spacing, device=device)\n",
    "nwp_loader = DataLoader(nwp_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed k sampling\n",
    "kmin = 1\n",
    "kmax = 150\n",
    "d = 1\n",
    "\n",
    "nwp_data_path = Path(f'C:/Users/svart/Desktop/MEX/data/QG_samples_LRES_Test_2101000_n_210000_1_k_150.npy')\n",
    "\n",
    "nwp_time_series_dataset = NWPTimeSeriesDataset(nwp_data_path, 'val', p_train, kmin, kmax, d, spinup, spacing, 210000, mean_data, std_data, device, dtype='float64', offset=2**7)\n",
    "nwp_time_series_loader = DataLoader(nwp_time_series_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WB Dataset\n",
    "\n",
    "batch_size = 256 # 256 Largest possible batch size that fits on the GPU w.f32\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "offset = 2**7\n",
    "\n",
    "mean_data = 54112.887 \n",
    "std_data = 3354.9524\n",
    "norm_factors = (mean_data, std_data)\n",
    "\n",
    "spacing = 1\n",
    "spinup = 0\n",
    "ti = pd.date_range(datetime.datetime(1979,1,1,0), datetime.datetime(2018,12,31,23), freq='1h')\n",
    "n_train = sum(ti.year <= 2015)\n",
    "n_val = sum((ti.year >= 2016) & (ti.year <= 2017))\n",
    "n_samples = len(ti)\n",
    "sample_counts = (n_samples, n_train, n_val)\n",
    "\n",
    "on_remote = False\n",
    "fname= 'geopotential_500hPa_1979-2018_5.625deg.npy'\n",
    "subd = 'C:/Users/svart/Desktop/MEX/data/'\n",
    "if on_remote:\n",
    "    #subd = '/nobackup/smhid20/users/sm_tland/wb1/geopotential_500'\n",
    "    subd = '/proj/berzelius-2022-164/users/sm_maran/data/wb'\n",
    "dataset_path = Path(f'{subd}/{fname}')\n",
    "\n",
    "grid_dimensions = (32, 64)\n",
    "max_lead_time = 240\n",
    "\n",
    "WB_kwargs = {\n",
    "            'dataset_path':     dataset_path,\n",
    "            'sample_counts':    sample_counts,\n",
    "            'grid_dimensions':  grid_dimensions,\n",
    "            'max_lead_time':    max_lead_time,\n",
    "            'norm_factors':     norm_factors,\n",
    "            'device':           device,\n",
    "            'spinup':           spinup,\n",
    "            'spacing':          spacing,\n",
    "            'dtype':            'float32',\n",
    "            'offset':           offset\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Way to load a dataset with a specific lead time\n",
    "lead_time = 1\n",
    "train_dataset = QGDataset(lead_time=lead_time,dataset_mode='train', **WB_kwargs)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Way to load a dataset with a specific lead time\n",
    "val_dataset = QGDataset(lead_time=lead_time, dataset_mode='val', **WB_kwargs)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Way to load a dataset with lead time following a distribution given by update_k_per_batch\n",
    "kmin = 1\n",
    "kmax = 240\n",
    "d = 1\n",
    "\n",
    "update_k_per_batch = get_uniform_k_dist_fn(kmin, kmax, d)\n",
    "\n",
    "train_time_dataset = QGDataset(lead_time=kmax, dataset_mode='train', **WB_kwargs)\n",
    "train_batch_sampler = DynamicKBatchSampler(train_time_dataset, batch_size=batch_size, drop_last=True, k_update_callback=update_k_per_batch, shuffle=True)\n",
    "train_time_loader = DataLoader(train_time_dataset, batch_sampler=train_batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Way to load a single trajectory. Only uses 1 batch.\n",
    "kmin = 1\n",
    "kmax = 240\n",
    "d = 1\n",
    "k_series = kmin + d * np.arange(0, 1 + (kmax-kmin)//d)\n",
    "\n",
    "val_time_series_dataset = QGDataset(lead_time=k_series, dataset_mode='val', **WB_kwargs)\n",
    "val_time_series_loader = DataLoader(val_time_series_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomputed_std = torch.tensor(np.loadtxt('stds/WB_stds.txt',delimiter=' ')[:,1], dtype=torch.float32).to(device)\n",
    "def residual_scaling(x):\n",
    "    return precomputed_std[x.to(dtype=int)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnm_ll = f'{subd}/latlon_500hPa_1979-2018_5.625deg.npz'\n",
    "buf = np.load(fnm_ll)\n",
    "lat, lon = buf['arr_0'], buf['arr_1']\n",
    "\n",
    "wmse = AreaWeightedMSELoss(lat, lon, device).loss_fn\n",
    "wmse_plot = AreaWeightedMSELoss(lat, lon, device).diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Autoencoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for training\n",
    "\n",
    "lambda_l1 = 0.00001\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "autoencoder = Autoencoder(filters= 32, no_latent_channels=1, no_downsamples=2, start_kernel=3)\n",
    "\n",
    "print(\"Num params: \", sum(p.numel() for p in autoencoder.parameters()))\n",
    "\n",
    "autoencoder.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(autoencoder.parameters(), lr=0.001, weight_decay=0.01)\n",
    "loss_fn = wmse #nn.L1Loss()\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "warmup_scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=0.001, end_factor=1.0, total_iters=1)\n",
    "loss_values = []\n",
    "val_loss_values = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Setup for logging\n",
    "log_file_path = 'results/autoencoder_training_log.csv'\n",
    "with open(log_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow(['Epoch', 'Average Training Loss', 'Validation Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_state_dict(torch.load('best_ae.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 1 + len(train_loader) // 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    autoencoder.train()\n",
    "    total_train_loss = 0\n",
    "    current_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    for previous, _, _ in tqdm(train_loader):\n",
    "        previous = previous.to(device)\n",
    "        \n",
    "        count += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        reconstruction, latent = autoencoder(previous)\n",
    "\n",
    "        reconstruction_loss = loss_fn(reconstruction, previous)\n",
    "        latent_loss = lambda_l1 * torch.mean(torch.norm(latent, 1, dim=1))\n",
    "\n",
    "        loss = reconstruction_loss + latent_loss\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        current_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if count % log_interval == 0:\n",
    "            current_loss = current_loss / count\n",
    "            print(f'Average Loss: {current_loss:.4f}')\n",
    "            current_loss = 0\n",
    "            count = 0\n",
    "        \n",
    "        warmup_scheduler.step()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    autoencoder.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for previous, _, _ in tqdm(val_loader):\n",
    "            previous = previous.to(device)\n",
    "                        \n",
    "            reconstruction, latent = autoencoder(previous)\n",
    "\n",
    "            reconstruction_loss = loss_fn(reconstruction, previous)\n",
    "            latent_loss = lambda_l1 * torch.mean(torch.norm(latent, 1, dim=1))\n",
    "\n",
    "            loss = reconstruction_loss + latent_loss\n",
    "            \n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(autoencoder.state_dict(), 'results/best_ae.pth')\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # Log to CSV    \n",
    "    loss_values.append([avg_train_loss])\n",
    "    val_loss_values.append(avg_val_loss)\n",
    "    \n",
    "    # Log to CSV\n",
    "    with open(log_file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([epoch+1, avg_train_loss, avg_val_loss])\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "    torch.save(autoencoder.state_dict(), 'results/final_ae.pth')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "loss_plot = np.array(loss_values)\n",
    "plt.plot(loss_plot[1:], label='Training Loss', color='blue')\n",
    "\n",
    "plt.plot(val_loss_values[1:], label='Validation Loss', color='red')\n",
    "plt.title('Loss as a Function of Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and axes for the subplot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "cmap1 = plt.cm.get_cmap('viridis', 30)\n",
    "\n",
    "batch,_,_ = next(iter(val_loader))\n",
    "batch = batch.to(device)\n",
    "reconstruction, _ = autoencoder(batch)\n",
    "data = batch[0]\n",
    "axes[0].imshow(data.cpu().detach().reshape(grid_dimensions), cmap=cmap1)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Original Data')\n",
    "\n",
    "reconstruction = reconstruction[0]\n",
    "axes[1].imshow(reconstruction.cpu().detach().reshape(grid_dimensions), cmap=cmap1)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[1].set_title('Reconstruction')\n",
    "diff = wmse_plot(data, reconstruction)\n",
    "axes[2].imshow(diff.cpu().detach().reshape(grid_dimensions))\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title('Difference')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and axes for the subplot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "cmap1 = plt.cm.get_cmap('viridis', 100)\n",
    "\n",
    "batch,_,_ = next(iter(val_loader))\n",
    "batch = batch.to(device)\n",
    "reconstruction, latent = autoencoder(batch)\n",
    "data = batch[0].cpu().detach().numpy()\n",
    "axes[0].imshow(data.reshape(grid_dimensions), cmap=cmap1)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Original Data')\n",
    "\n",
    "reconstruction = reconstruction[0].cpu().detach().numpy()\n",
    "axes[1].imshow(reconstruction.reshape(grid_dimensions), cmap=cmap1)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Reconstruction')\n",
    "\n",
    "latent = latent[0].cpu().detach().numpy()\n",
    "axes[2].imshow(latent[0], cmap=cmap1)\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title('Latent')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Diffusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Autoencoder\n",
    "autoencoder_date = '2024-02-21'\n",
    "autoencoder_model = 'ae-2ds-32f-1l-150e-L1-0wd-0.00001l1'\n",
    "\n",
    "autoencoder_path = Path(f'/nobackup/smhid20/users/sm_maran/results/{autoencoder_date}/{autoencoder_model}/') if on_remote else Path(f'C:/Users/svart/Desktop/MEX/results/{autoencoder_date}/{autoencoder_model}/')\n",
    "saved_model = torch.load(autoencoder_path / 'best_model.pth')\n",
    "\n",
    "with open(autoencoder_path / 'config.json', 'r') as json_file:\n",
    "    parameters = json.load(json_file)\n",
    "\n",
    "filters = parameters['filters']\n",
    "latent_dim = parameters['latent_dim']\n",
    "no_downsamples = parameters['no_downsamples']\n",
    "\n",
    "autoencoder = Autoencoder(filters= filters, no_latent_channels=latent_dim, no_downsamples=no_downsamples)\n",
    "autoencoder.load_state_dict(saved_model)\n",
    "autoencoder.to(device)\n",
    "autoencoder.eval()\n",
    "\n",
    "print(\"Autoencoder loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Diffusion model\n",
    "diffusion_date = '2024-02-29'\n",
    "result_model = f'ncsnpp-f32-k{k}'\n",
    "\n",
    "result_path = Path(f'/nobackup/smhid20/users/sm_maran/results/{diffusion_date}/{result_model}/') if on_remote else Path(f'C:/Users/svart/Desktop/MEX/results/{diffusion_date}/{result_model}/')\n",
    "saved_model = torch.load(result_path / 'best_model.pth')\n",
    "\n",
    "with open(result_path / 'config.json', 'r') as json_file:\n",
    "    parameters = json.load(json_file)\n",
    "\n",
    "filters = parameters['filters']\n",
    "model_name = parameters['model']\n",
    "k = parameters['k']\n",
    "\n",
    "forecasting = True\n",
    "model = GCPrecond(filters=filters, img_channels=2 if forecasting else 1, model='ncsnppOriginal', img_resolution = 16, time_emb=0)\n",
    "\n",
    "model.load_state_dict(saved_model)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Diffusion Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_latent_mean_std():\n",
    "    # Calculate mean and var\n",
    "    # Initialize variables for mean and standard deviation\n",
    "    mean_data_latent = 0.0\n",
    "    std_data_latent = 0.0\n",
    "    count = 0\n",
    "    #autoencoder.to('cpu')\n",
    "    # Iterate over the batches in train_loader\n",
    "    autoencoder.eval()\n",
    "    with torch.no_grad():\n",
    "        for current, next,_ in train_loader:\n",
    "            # Get the input data from the batch\n",
    "            current = current.to(device)\n",
    "            next = next.to(device)\n",
    "            latent = autoencoder.encoder(current)\n",
    "            next_latent = autoencoder.encoder(next)\n",
    "            \n",
    "            inputs = next_latent -  latent\n",
    "\n",
    "            count += inputs.size(0)\n",
    "\n",
    "            # Calculate the sum of the input data\n",
    "            mean_data_latent += torch.sum(inputs)\n",
    "            std_data_latent += torch.sum(inputs ** 2)\n",
    "            #print(mean_data_latent/count, std_data_latent/count, count)\n",
    "            break\n",
    "            \n",
    "        # Calculate the mean and standard deviation\n",
    "        count = count * inputs[0].cpu().detach().numpy().size\n",
    "        # TODO\n",
    "        mean_data_latent /= count\n",
    "        std_data_latent = torch.sqrt(std_data_latent / count - mean_data_latent ** 2)\n",
    "\n",
    "        # Print the mean and standard deviation\n",
    "        #print(\"Mean:\", mean_data_latent.item())\n",
    "        #print(\"Standard Deviation:\", std_data_latent.item())\n",
    "\n",
    "    return mean_data_latent, std_data_latent\n",
    "\n",
    "mean_data_latent, std_data_latent = calculate_latent_mean_std()\n",
    "print(mean_data_latent, std_data_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Way to load a dataset with a specific lead time\n",
    "lead_time = 1\n",
    "train_dataset = QGDataset(lead_time=lead_time,dataset_mode='train', **WB_kwargs)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
    "\n",
    "# Fit the residual scaling\n",
    "ks = np.arange(1, max_lead_time, 1)\n",
    "stds = []\n",
    "for k in ks:\n",
    "    train_dataset.set_lead_time(k)\n",
    "\n",
    "    _, std_latent_k = calculate_latent_mean_std()\n",
    "    stds.append(std_latent_k.item())\n",
    "    print(k, std_latent_k.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ks[:]\n",
    "y = stds[:]\n",
    "\n",
    "\n",
    "# Plotting the original data and the fitted models\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(x, y, color='blue', label='Data points', marker='.')\n",
    "#plt.plot(x, y_fitted_log, color='red', label='Log Model')\n",
    "#plt.plot(x, y_fitted_logistic, color='green', label='Logistic Model')\n",
    "plt.title('Data Points with Fitted Models')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area-weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for training\n",
    "\n",
    "forecasting = True\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "model = EDMPrecond(filters=32, img_channels=2 if forecasting else 1, img_resolution = 16, time_emb=1, model_type='standard', sigma_data=1, sigma_min=0.02, sigma_max=88)\n",
    "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "model.to(device)\n",
    " \n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.1)\n",
    "loss_fn = GCLoss(time_noise=0)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "warmup_scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=0.001, end_factor=1.0, total_iters=1000)\n",
    "loss_values = []\n",
    "val_loss_values = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Setup for logging\n",
    "log_file_path = 'results/training_log.csv'\n",
    "with open(log_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow(['Epoch', 'Average Training Loss', 'Validation Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('models/240414k1-150-100ep.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = len(train_time_loader) // 4\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    current_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    for previous, current, time_label in tqdm(train_time_loader):\n",
    "        current = current.to(device)\n",
    "        previous = previous.to(device)\n",
    "        time_label = time_label.to(device)\n",
    "        \n",
    "        count += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            current_latent = autoencoder.encoder(current)\n",
    "\n",
    "            previous_latent = autoencoder.encoder(previous)\n",
    "            target_latent = (current_latent - previous_latent) / residual_scaling(time_label[0])\n",
    "            \n",
    "        loss = loss_fn(model, target_latent, previous_latent, time_label/max_lead_time)\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        current_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if count % log_interval == 0:\n",
    "            current_loss = current_loss / count\n",
    "            print(f'Average Loss: {current_loss:.4f}')\n",
    "            current_loss = 0\n",
    "            count = 0\n",
    "        \n",
    "        warmup_scheduler.step()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_time_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for previous, current, time_label in tqdm(val_loader):\n",
    "            current = current.to(device)\n",
    "            previous = previous.to(device)\n",
    "            time_label = time_label.to(device)\n",
    "            \n",
    "            current_latent = autoencoder.encoder(current)\n",
    "\n",
    "            previous_latent = autoencoder.encoder(previous)\n",
    "            target_latent = (current_latent - previous_latent) / residual_scaling(time_label[0])\n",
    "            \n",
    "            loss = loss_fn(model, target_latent, previous_latent, time_label/max_lead_time)\n",
    "            \n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'results/best_model.pth')\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # Log to CSV    \n",
    "    loss_values.append([avg_train_loss])\n",
    "    val_loss_values.append(avg_val_loss)\n",
    "    \n",
    "    # Log to CSV\n",
    "    with open(log_file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([epoch+1, avg_train_loss, avg_val_loss])\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "    torch.save(model.state_dict(), 'final_model.pth')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "loss_plot = np.array(loss_values)\n",
    "plt.plot(loss_plot[1:], label='Training Loss', color='blue')\n",
    "\n",
    "plt.plot(val_loss_values[1:], label='Validation Loss', color='red')\n",
    "plt.title('Loss as a Function of Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ensemble_from_single_random(model, n_ens=10, selected_loader = val_loader, sampler_fn=heun_sampler):\n",
    "    model.eval()\n",
    "\n",
    "    for previous, current, time_label in selected_loader:\n",
    "        time_labels = torch.ones(n_ens, device=device, dtype=int) * time_label[0]\n",
    "        previous_unbatched = previous[0].unsqueeze(0).to(device)\n",
    "        current_unbatched = current[0].unsqueeze(0).to(device)\n",
    "        break\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        previous_latent = autoencoder.encoder(previous_unbatched)\n",
    "\n",
    "        class_labels = previous_latent.repeat(n_ens, 1, 1, 1)\n",
    "        \n",
    "        latents = torch.randn_like(class_labels, device=device)\n",
    "        #latents = torch.randn_like(previous_latent, device=device).repeat(n_ens, 1, 1, 1)\n",
    "\n",
    "        predicted_residuals = sampler_fn(model, latents, class_labels, time_labels / max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20, S_churn=2.5, S_min=0.75, S_max=80, S_noise=1.05)\n",
    "        predicted_latent = previous_latent + predicted_residuals * residual_scaling(time_label[0])\n",
    "        \n",
    "        predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "\n",
    "        predicted_unnormalized = predicted * std_data + mean_data\n",
    "        current_unnormalized = current_unbatched * std_data + mean_data\n",
    "        previous_unnormalized = previous_unbatched * std_data + mean_data\n",
    "\n",
    "        predicted_unnormalized = predicted_unnormalized.view(n_ens, 1, previous.size(1), previous.size(2), previous.size(3))\n",
    "\n",
    "    return predicted_unnormalized, current_unnormalized, previous_unnormalized\n",
    "\n",
    "#predicted_unnormalized, current_unnormalized, previous_unnormalized = generate_ensemble_from_single_random(model, n_ens=10, selected_loader = val_loader, sampler_fn=heun_sampler)\n",
    "\n",
    "def generate_ar_ensemble_from_single_random(model, rollout, n_ens=10, selected_loader = val_loader, sampler_fn=heun_sampler):\n",
    "    model.eval()\n",
    "\n",
    "    for previous, current, time_label in selected_loader:\n",
    "        time_labels = torch.ones(n_ens, device=device, dtype=int) * time_label[0]\n",
    "        previous_unbatched = previous[0].unsqueeze(0).to(device)\n",
    "        current_unbatched = current[0].unsqueeze(0).to(device)\n",
    "        break\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        previous_latent = autoencoder.encoder(previous_unbatched)\n",
    "\n",
    "        class_labels = previous_latent.repeat(n_ens, 1, 1, 1)\n",
    "        \n",
    "        latents = torch.randn_like(class_labels, device=device)\n",
    "\n",
    "        for i in range(rollout):\n",
    "            predicted_residuals = sampler_fn(model, latents, class_labels, time_labels / max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20, S_churn=2.5, S_min=0.75, S_max=80, S_noise=1.05)\n",
    "\n",
    "            predicted_latent = class_labels + predicted_residuals * residual_scaling(time_label[0])\n",
    "            \n",
    "            class_labels = predicted_latent\n",
    "        \n",
    "        predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "\n",
    "        predicted_unnormalized = predicted * std_data + mean_data\n",
    "        current_unnormalized = current_unbatched * std_data + mean_data\n",
    "        previous_unnormalized = previous_unbatched * std_data + mean_data\n",
    "\n",
    "        predicted_unnormalized = predicted_unnormalized.view(n_ens, 1, previous.size(1), previous.size(2), previous.size(3))\n",
    "\n",
    "    return predicted_unnormalized, current_unnormalized, previous_unnormalized\n",
    "\n",
    "#predicted_unnormalized, current_unnormalized, previous_unnormalized = generate_ar_ensemble_from_single_random(model, rollout=2, n_ens=10, selected_loader = val_loader, sampler_fn=heun_sampler)\n",
    "\n",
    "def generate_ensemble_from_batch(model, previous, lead_time, n_ens=10, sampler_fn=heun_sampler):\n",
    "    # Need to choose batch_size such that batch_size*n_ens fits on GPU\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        previous = previous.to(device)\n",
    "        previous_latent = autoencoder.encoder(previous)\n",
    "        class_labels = previous_latent.repeat(n_ens, 1, 1, 1)\n",
    "        time_labels = torch.ones(class_labels.shape[0], device=device, dtype=int) * lead_time / max_lead_time\n",
    "\n",
    "        latents = torch.randn_like(class_labels, device=device)\n",
    "\n",
    "        predicted_residuals = sampler_fn(model, latents, class_labels, time_labels, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20, S_churn=2.5, S_min=0.75, S_max=80, S_noise=1.05)\n",
    "\n",
    "        predicted_latent = class_labels + predicted_residuals * residual_scaling(torch.tensor(lead_time))\n",
    "        predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "\n",
    "        predicted_unnormalized = predicted * std_data + mean_data\n",
    "\n",
    "        predicted_unnormalized = predicted_unnormalized.view(n_ens, previous.size(0), previous.size(1), previous.size(2), previous.size(3))\n",
    "\n",
    "    return predicted_unnormalized\n",
    "\n",
    "#predicted_unnormalized = generate_ensemble_from_batch(model, next(iter(val_loader))[0], lead_time, n_ens=1)\n",
    "\n",
    "def generate_ar_ensemble_from_batch(model, previous, lead_time, rollout, n_ens=10, sampler_fn=heun_sampler):\n",
    "    # Need to choose batch_size such that batch_size*n_ens fits on GPU\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        previous = previous.to(device)\n",
    "        previous_latent = autoencoder.encoder(previous)\n",
    "        class_labels = previous_latent.repeat(n_ens, 1, 1, 1)\n",
    "        time_labels = torch.ones(class_labels.shape[0], device=device, dtype=int) * lead_time / max_lead_time\n",
    "        latents = torch.randn_like(class_labels, device=device)\n",
    "\n",
    "        for i in range(rollout):\n",
    "            predicted_residuals = sampler_fn(model, latents, class_labels, time_labels, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20, S_churn=2.5, S_min=0.75, S_max=80, S_noise=1.05)\n",
    "\n",
    "            predicted_latent = class_labels + predicted_residuals * residual_scaling(torch.tensor(lead_time))\n",
    "            \n",
    "            class_labels = predicted_latent\n",
    "        \n",
    "        predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "\n",
    "        predicted_unnormalized = predicted * std_data + mean_data\n",
    "\n",
    "        predicted_unnormalized = predicted_unnormalized.view(n_ens, previous.size(0), previous.size(1), previous.size(2), previous.size(3))\n",
    "\n",
    "    return predicted_unnormalized\n",
    "\n",
    "#predicted_unnormalized = generate_ar_ensemble_from_batch(model, next(iter(val_loader))[0], lead_time=10, rollout=3, n_ens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Calculations***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batched input (n_ens, batch_size, img_channels, img_resolution, img_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does work for unbatched data currently\n",
    "forecast, truth, _ = generate_ensemble_from_single_random(model, n_ens=10, selected_loader = train_loader, sampler_fn=heun_sampler)\n",
    "skill, spread, ratio = calculate_skill_and_spread_score(forecast, truth)\n",
    "crps = calculate_CRPS(forecast, truth)\n",
    "brier = calculate_brier_score(forecast, truth, 20)\n",
    "\n",
    "\n",
    "print(f\"Skill: {skill[0]:.2f}, Spread: {spread[0]:.2f}, Ratio: {ratio[0]:.3f}, CRPS: {crps[0]:.3f}, Brier: {brier[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be relative to climatology we need it to be just for a single season.\n",
    "\n",
    "clim = climatology * std_data + mean_data\n",
    "calculate_RMSE(clim, truth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_pipeline(model, n_ens=10, n_batches=1, batch_size=10, selected_loader=val_loader, sampler_fn=edm_sampler, rollouts=None):\n",
    "    model.eval()\n",
    "\n",
    "    #climatology = calculate_climatology(selected_loader)\n",
    "\n",
    "    results = {\n",
    "                'skill': np.zeros(n_batches*batch_size),\n",
    "                'spread': np.zeros(n_batches*batch_size),\n",
    "                'ratio': np.zeros(n_batches*batch_size),\n",
    "                'crps': np.zeros(n_batches*batch_size),\n",
    "                'brier': np.zeros(n_batches*batch_size),\n",
    "                'covtrace': np.zeros(n_batches*batch_size),\n",
    "                'psnr': np.zeros(n_batches*batch_size),\n",
    "                #'acc': np.zeros(n_batches*batch_size),\n",
    "                }\n",
    "    \n",
    "    results['rmse'] = np.zeros((n_ens, n_batches*batch_size))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for count, (previous, current, time_label) in (enumerate(tqdm(selected_loader, total=n_batches))):\n",
    "            if count >= n_batches:\n",
    "                break\n",
    "            \n",
    "            previous = previous.to(device)\n",
    "            current = current.to(device)\n",
    "            if rollouts is None:\n",
    "                predicted_unnormalized = generate_ensemble_from_batch(model, previous, time_label[0], n_ens=n_ens, sampler_fn=sampler_fn)\n",
    "            else:\n",
    "                if time_label[0]%rollouts != 0:\n",
    "                    raise ValueError(\"Lead time must be a multiple of rollouts\")\n",
    "\n",
    "                predicted_unnormalized = generate_ar_ensemble_from_batch(model, previous, lead_time=time_label[0]//rollouts, rollout=rollouts, n_ens=n_ens, sampler_fn=sampler_fn)\n",
    "\n",
    "            current_unnormalized = current * std_data + mean_data\n",
    "\n",
    "            # = calculate_ACC(predicted_unnormalized, current_unnormalized, climatology)\n",
    "            rmse = calculate_RMSE(predicted_unnormalized, current_unnormalized)\n",
    "\n",
    "            skill, spread, ratio = calculate_skill_and_spread_score(predicted_unnormalized, current_unnormalized)\n",
    "            crps = calculate_CRPS(predicted_unnormalized, current_unnormalized)\n",
    "            brier = calculate_brier_score(predicted_unnormalized, current_unnormalized, 20)\n",
    "            #covtrace = calculate_covtrace(predicted_unnormalized)    \n",
    "            psnr = calculate_psnr(predicted_unnormalized, current_unnormalized)\n",
    "            # Can make this easier by preallocating results\n",
    "            results['skill'][count*batch_size:(count+1)*batch_size] = skill\n",
    "            results['spread'][count*batch_size:(count+1)*batch_size] = spread\n",
    "            results['ratio'][count*batch_size:(count+1)*batch_size] = ratio\n",
    "            results['crps'][count*batch_size:(count+1)*batch_size] = crps\n",
    "            results['brier'][count*batch_size:(count+1)*batch_size] = brier\n",
    "            #results['covtrace'][count*batch_size:(count+1)*batch_size] = covtrace\n",
    "            results['psnr'][count*batch_size:(count+1)*batch_size] = psnr\n",
    "            #results['acc'][count*batch_size:(count+1)*batch_size] = ACC\n",
    "\n",
    "            results['rmse'][:,count*batch_size:(count+1)*batch_size] = rmse\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time = 10\n",
    "btch_sz = 20\n",
    "n_ens = 50\n",
    "n_batches = 1\n",
    "rollouts = None\n",
    "\n",
    "test_dataset = QGDataset(lead_time=lead_time, dataset_mode='test', **WB_kwargs)\n",
    "test_loader = DataLoader(test_dataset, batch_size=btch_sz, shuffle=False)\n",
    "\n",
    "res = evaluation_pipeline(model, n_ens=n_ens, n_batches=n_batches, batch_size=btch_sz, selected_loader=test_loader, sampler_fn=heun_sampler, rollouts=rollouts)\n",
    "\n",
    "print(f\"Skill: {np.mean(res['skill']):.2f}, Spread: {np.mean(res['spread']):.2f}, Ratio: {np.mean(res['ratio']):.3f}, CRPS: {np.mean(res['crps']):.3f}, Brier: {np.mean(res['brier']):.4f}, PSNR: {np.mean(res['psnr']):.2f}, RMSE: {np.mean(res['rmse']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_climatology(selected_loader, n_batches=None):\n",
    "    mean = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for _, current,_ in tqdm(selected_loader):\n",
    "            current = current.to(device)\n",
    "            if n_batches != None:\n",
    "                if count >= n_batches:\n",
    "                    break\n",
    "            mean += torch.sum(current, dim=0)\n",
    "            count += 1\n",
    "    \n",
    "    count = count * current.size(0)\n",
    "    mean = mean / count\n",
    "\n",
    "    return mean.unsqueeze(0)\n",
    "\n",
    "climatology = calculate_climatology(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QG NWP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to calculate nwp skill and climatology.\n",
    "Not the best code, nwp_dataset should really be updated if we want to use it properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For QG NWP\n",
    "\n",
    "def calculate_nwp_skill(n_batches=2, selected_loader=val_loader):\n",
    "    count = 0\n",
    "\n",
    "    results = {'skill': [],\n",
    "               'psnr': [],\n",
    "               }\n",
    "\n",
    "\n",
    "    for (previous, current, _), nwp in zip(selected_loader, nwp_loader):\n",
    "        print(count)\n",
    "        if count >= n_batches:\n",
    "            break\n",
    "        \n",
    "        current = current.to(device)\n",
    "        nwp = nwp.to(device)\n",
    "        current_unnormalized = current * std_data + mean_data\n",
    "\n",
    "        skill = calculate_RMSE(nwp, current_unnormalized).flatten()\n",
    "        psnr = calculate_psnr(nwp.unsqueeze(0), current_unnormalized).flatten()\n",
    "        results['skill'].append(skill)\n",
    "        results['psnr'].append(psnr)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    results = {key: np.concatenate(value) for key, value in results.items()}\n",
    "\n",
    "    # Just return skill for now\n",
    "    return results['skill'], results['psnr']\n",
    "\n",
    "def calculate_climatology(selected_loader, n_batches=2):\n",
    "    mean = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for _, current,_ in tqdm(selected_loader):\n",
    "            current = current.to(device)\n",
    "            if count >= n_batches:\n",
    "                break\n",
    "            mean += torch.sum(current, dim=0)\n",
    "            count += 1\n",
    "    \n",
    "    count = count * current.size(0)\n",
    "    mean = mean / count\n",
    "\n",
    "    return mean.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val = 210000\n",
    "nwp_lead_time = 150\n",
    "\n",
    "# Way to load a dataset with a specific lead time\n",
    "test_compare_dataset = QGDataset(lead_time=nwp_lead_time, dataset_mode='val', **QG_kwargs)\n",
    "test_compare_loader = DataLoader(test_compare_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "nwp_data_path = Path(f'/nobackup/smhid20/users/sm_maran/dpr_data/simulations/QG_samples_LRES_{iterations}_n_{n_val}_k_{nwp_lead_time}.npy') if on_remote else Path(f'C:/Users/svart/Desktop/MEX/data/QG_samples_LRES_{iterations}_n_{n_val}_k_{nwp_lead_time}.npy')\n",
    "\n",
    "nwp_dataset = NWPDataset(nwp_data_path, n_val=n_val, spacing=spacing, device=device)\n",
    "nwp_loader = DataLoader(nwp_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#climatology = calculate_climatology(train_loader, n_batches=10)\n",
    "nwp_skill, nwp_psnr = calculate_nwp_skill(n_batches=10, selected_loader=test_compare_loader)\n",
    "\n",
    "print(f\"Skill: {np.mean(nwp_skill):.2f}, PSNR: {np.mean(nwp_psnr):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot functions\n",
    "def plot_global(ax, image):\n",
    "    #ax = plt.axes(projection=ccrs.Robinson())\n",
    "    ax.pcolormesh(lon, lat, image, transform=ccrs.PlateCarree(), cmap=cmap)\n",
    "    ax.coastlines(resolution='110m')\n",
    "    ax.gridlines()\n",
    "\n",
    "def plot_grid(image):\n",
    "    plt.imshow(image, cmap=cmap)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt_fn = plot_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = next(iter(train_loader))\n",
    "image = temp[1][0,0]\n",
    "fig, axes = plt.subplots(1, 1, figsize=(4, 4), subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "plt_fn(axes, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **States**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **State:** Denoising of states over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_denoising_of_states():\n",
    "    \"\"\"\n",
    "    Plot the denoising of random states\n",
    "    \"\"\"\n",
    "    image =  next(iter(train_loader))[0][0,0] #* std_data + mean_data\n",
    "\n",
    "    noisy_images = []\n",
    "    max_num = 6\n",
    "    for i in range(max_num):\n",
    "\n",
    "        rnd_uniform = 1 - i/(max_num-1)\n",
    "        rho_inv = 1 / 7\n",
    "        sigma_max_rho = 88 ** rho_inv\n",
    "        sigma_min_rho = 0.02 ** rho_inv\n",
    "        \n",
    "        sigma = (sigma_max_rho + rnd_uniform * (sigma_min_rho - sigma_max_rho)) ** 7\n",
    "\n",
    "        weight = (sigma ** 2 + 1 ** 2) / (sigma * 1) ** 2\n",
    "\n",
    "        noise = torch.randn_like(image)\n",
    "        noisy_image = image + sigma * noise\n",
    "        \n",
    "        noisy_images.append(noisy_image.cpu().detach().numpy())\n",
    "\n",
    "    fig, axes = plt.subplots(1, max_num, figsize=(20, 4))\n",
    "    for i in range(max_num):\n",
    "        axes[i].imshow(noisy_images[i], cmap=cmap)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('figures/noisy_images.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_denoising_of_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **State:** Autoencoder comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image =  next(iter(train_loader))[0] #* std_data + mean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = autoencoder.encoder(image.to(device)).detach().cpu()\n",
    "reconstruction = autoencoder.decoder(encoded.to(device)).detach().cpu()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "ax.imshow(reconstruction[0,0], cmap=cmap)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figures/reconstruction.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **State:** Removing noise from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = next(iter(train_loader))\n",
    "image = temp[1][0,0]\n",
    "cond = temp[0][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_denoising_of_states():\n",
    "    \"\"\"\n",
    "    Plot the denoising of random states\n",
    "    \"\"\"\n",
    "    #image =  next(iter(train_loader))[0][0,0] #* std_data + mean_data\n",
    "\n",
    "    noisy_images = []\n",
    "    max_num = 4\n",
    "    for i in range(max_num):\n",
    "\n",
    "        rnd_uniform = 1 - i/(max_num-1)\n",
    "        rho_inv = 1 / 7\n",
    "        sigma_max_rho = 88 ** rho_inv\n",
    "        sigma_min_rho = 0.02 ** rho_inv\n",
    "        \n",
    "        sigma = (sigma_max_rho + rnd_uniform * (sigma_min_rho - sigma_max_rho)) ** 7\n",
    "\n",
    "        weight = (sigma ** 2 + 1 ** 2) / (sigma * 1) ** 2\n",
    "\n",
    "        noise = torch.randn_like(image)\n",
    "        noisy_image = image + sigma * noise\n",
    "        \n",
    "        noisy_images.append(noisy_image.cpu().detach().numpy())\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(4, 4))#, subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "    #plt_fn(axes,noisy_images[3])\n",
    "    axes.imshow(noisy_images[3] - noisy_images[0], cmap=cmap)\n",
    "    #axes.imshow(cond, cmap=cmap)\n",
    "    #axes.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('figures/noise3.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_denoising_of_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **State:** Standard plot of ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard plot of ensembles\n",
    "\n",
    "def ensemble_plot(model, selected_loader=val_loader, n_ens=10, sampler_fn=heun_sampler):\n",
    "    \n",
    "    lead_time = selected_loader.dataset.lead_time\n",
    "    predicted_unnormalized, current_unnormalized, previous_unnormalized = generate_ensemble_from_single_random(model, n_ens, selected_loader, sampler_fn=sampler_fn)\n",
    "\n",
    "    ensemble_mean = predicted_unnormalized.mean(dim=0, keepdim=True)\n",
    "    ensemble_rmses = calculate_RMSE(predicted_unnormalized, current_unnormalized).flatten()\n",
    "    ensemble_skill = calculate_RMSE(ensemble_mean, current_unnormalized).item()\n",
    "    ensemble_std = predicted_unnormalized.std(dim=0)\n",
    "\n",
    "    best_forecast = predicted_unnormalized[np.argmin(ensemble_rmses)]\n",
    "    best_rmse = ensemble_rmses[np.argmin(ensemble_rmses)]\n",
    "\n",
    "    def plot_image(ax, image, title):\n",
    "        image = image.cpu().detach().numpy().reshape((current_unnormalized.shape[2],current_unnormalized.shape[3]))\n",
    "        ax.imshow(image, cmap=cmap)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.set_cmap('viridis')\n",
    "    no_ens_rows = 2\n",
    "\n",
    "    fig, axes = plt.subplots(1+no_ens_rows, 5, figsize=(15, 10))\n",
    "    fig.suptitle(f'{lead_time} step ahead prediction, {n_ens} ensemble members')\n",
    "\n",
    "    plot_image(axes[0,0], previous_unnormalized, \"Previous\")\n",
    "    plot_image(axes[0,1], current_unnormalized, \"Truth\")\n",
    "    plot_image(axes[0,2], ensemble_mean, f\"{ensemble_skill:.2f}\\nEnsemble Mean\")\n",
    "    plot_image(axes[0,3], best_forecast, f\"{best_rmse:.2f}\\nBest forecast\")\n",
    "    plot_image(axes[0,4], ensemble_std, \"Ensemble Std\")\n",
    "\n",
    "    count = 0\n",
    "    for i in range(no_ens_rows):\n",
    "        for j in range(5):\n",
    "            plot_image(axes[1+i,j], predicted_unnormalized[count], f\"{ensemble_rmses[count]:.2f}\")\n",
    "            count+=1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return ensemble_rmses, ensemble_skill\n",
    "\n",
    "val_dataset.set_lead_time(36)\n",
    "\n",
    "ensemble_rmses, ensemble_skill = ensemble_plot(model, selected_loader=val_loader, n_ens=10, sampler_fn=heun_sampler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **State:** Forecast at single future time like GenCast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that the split results in same distance between all.\n",
    "# Otherwise it becomes wrong when we flip it.\n",
    "\n",
    "# Way to load a single trajectory. Only uses 1 batch.\n",
    "t_kmin = 0\n",
    "t_kmax = 150\n",
    "t_d = 25\n",
    "\n",
    "k_series = t_kmin + t_d * np.arange(0, 1 + (t_kmax-t_kmin)//t_d)\n",
    "val_time_series_dataset = QGDataset(lead_time=k_series, dataset_mode='val', **QG_kwargs)\n",
    "val_time_series_loader = DataLoader(val_time_series_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    for previous, current, time_label in (val_time_series_loader):\n",
    "        current = current.to(device).permute(1,0,2,3)\n",
    "\n",
    "        current_last = current[-1].unsqueeze(0).repeat(current.shape[0]-1, 1, 1, 1)\n",
    "        current_latent = autoencoder.encoder(current_last)\n",
    "\n",
    "        time_labels = time_label[0].flip([0])[:-1].to(device)\n",
    "        \n",
    "        previous_latent = autoencoder.encoder(current[:-1])\n",
    "        \n",
    "        scaling = residual_scaling(time_labels).view(-1, 1, 1, 1)\n",
    "        target_latent =  (current_latent - previous_latent) / scaling\n",
    "        \n",
    "        class_labels = previous_latent\n",
    "\n",
    "        current_unnormalized = current_last * std_data + mean_data\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ens = 500\n",
    "\n",
    "ensembles = []\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i in tqdm(range(n_ens)):    \n",
    "        latents = torch.randn_like(class_labels[0], device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "        predicted_residuals = heun_sampler(model, latents, class_labels, time_labels/max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20)\n",
    "        predicted_latent = previous_latent + predicted_residuals * scaling\n",
    "\n",
    "        predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "\n",
    "        predicted_unnormalized = predicted * std_data + mean_data\n",
    "\n",
    "        ensembles.append(predicted_unnormalized)\n",
    "\n",
    "ensembles = torch.stack(ensembles)\n",
    "ens_mean = ensembles.mean(dim=0)\n",
    "ens_std = ensembles.std(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def plot_image(ax, image, title=None, vmin=None, vmax=None):\n",
    "    image = image.cpu().detach().numpy().reshape((image.shape[1],image.shape[2]))\n",
    "    ax.imshow(image,vmin=vmin, vmax=vmax, cmap=cmap, interpolation='none')\n",
    "    if title!=None:\n",
    "        ax.set_title(title)\n",
    "    #ax.axis('off')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "no_ens_rows = ensembles.shape[1]\n",
    "\n",
    "cols = 6 + 2\n",
    "col_width_ratios = [1, 0, 1, 1, 1, 0, 1, 1]\n",
    "gs = gridspec.GridSpec(no_ens_rows, cols, width_ratios=col_width_ratios)\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "axes = np.empty((no_ens_rows, cols), dtype=object)\n",
    "for i in range(no_ens_rows):\n",
    "    for j in range(cols):\n",
    "        axes[i,j] = plt.subplot(gs[i,j])\n",
    "\n",
    "max_value = ensembles[:3].max()\n",
    "min_value = ensembles[:3].min()\n",
    "\n",
    "plot_image(axes[0,0], current_unnormalized[-1], \"Truth\", vmin=min_value, vmax=max_value)\n",
    "\n",
    "for j in range(1, 4):\n",
    "    axes[0,j+1].set_title(f\"Sample #{j}\")\n",
    "axes[0,6].set_title(\"Ensemble Mean\")\n",
    "axes[0,7].set_title(f\"Ensemble Std\")\n",
    "\n",
    "\n",
    "for i in range(no_ens_rows):\n",
    "    if i > 0:\n",
    "        axes[i,0].axis('off')\n",
    "    axes[i,1].text(1.18,0.5, f\"Forecast from\\n {time_labels[-(i+1)].item()}t earlier\", horizontalalignment='center', verticalalignment='center', rotation=90, transform=axes[i,0].transAxes)\n",
    "    \n",
    "    axes[i,1].axis('off')\n",
    "    axes[i,5].axis('off')\n",
    "\n",
    "    for j in range(1, 4):\n",
    "        plot_image(axes[i,j+1], ensembles[j,-(i+1)], vmin=min_value, vmax=max_value)\n",
    "    plot_image(axes[i,6], ens_mean[-(i+1)], vmin=min_value, vmax=max_value)\n",
    "    plot_image(axes[i,7], ens_std[-(i+1)], vmin=0, vmax=ens_std.max())\n",
    "\n",
    "\n",
    "plt.savefig('figures/large_ensemble_plot.pdf', dpi=100, format='pdf', bbox_inches='tight')#, pad_inches=0.1, transparent=True, quality=95, optimize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **State:** Forecast over lead time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_kmin = 50\n",
    "t_kmax = 150\n",
    "t_d = 50\n",
    "\n",
    "k_series = t_kmin + t_d * np.arange(0, 1 + (t_kmax-t_kmin)//t_d)\n",
    "val_time_series_dataset = QGDataset(lead_time=k_series, dataset_mode='val', **QG_kwargs)\n",
    "val_time_series_loader = DataLoader(val_time_series_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    for previous, current, time_label in (val_time_series_loader):\n",
    "        current = current.to(device).permute(1,0,2,3)\n",
    "        previous = previous.to(device)\n",
    "\n",
    "        current_latent = autoencoder.encoder(current)\n",
    "\n",
    "        time_labels = time_label[0].to(device)\n",
    "        \n",
    "        previous_latent = autoencoder.encoder(previous)\n",
    "        \n",
    "        scaling = residual_scaling(time_labels).view(-1, 1, 1, 1)\n",
    "        target_latent =  (current_latent - previous_latent) / scaling\n",
    "        \n",
    "        class_labels = previous_latent.repeat(current.shape[0], 1, 1, 1)\n",
    "\n",
    "        current_unnormalized = current * std_data + mean_data\n",
    "        previous_unnormalized = previous * std_data + mean_data\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ens = 3\n",
    "\n",
    "ensembles = []\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i in tqdm(range(n_ens)):    \n",
    "        latents = torch.randn_like(class_labels[0], device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "        predicted_residuals = heun_sampler(model, latents, class_labels, time_labels/max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20)\n",
    "        predicted_latent = previous_latent + predicted_residuals * scaling\n",
    "\n",
    "        predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "\n",
    "        predicted_unnormalized = predicted * std_data + mean_data\n",
    "\n",
    "        ensembles.append(predicted_unnormalized)\n",
    "\n",
    "ensembles = torch.stack(ensembles)\n",
    "ens_mean = ensembles.mean(dim=0)\n",
    "ens_std = ensembles.std(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "def plot_image(ax, image, title=None, vmin=None, vmax=None):\n",
    "    image = image.cpu().detach().numpy().reshape((image.shape[1],image.shape[2]))\n",
    "    ax.imshow(image,vmin=vmin, vmax=vmax, cmap=cmap, interpolation='none')\n",
    "    if title!=None:\n",
    "        ax.set_title(title)\n",
    "    #ax.axis('off')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "def place_text(ax, text):\n",
    "    ax.text(-0.1,0.5, text, horizontalalignment='center', verticalalignment='center', rotation=90, transform=ax.transAxes)\n",
    "\n",
    "max_value = max([ensembles[:3].max(), current_unnormalized.max(), ens_mean.max()])\n",
    "min_value = min([ensembles[:3].min(), current_unnormalized.min(), ens_mean.min()])\n",
    "\n",
    "no_ens_rows =  ensembles.shape[1]\n",
    "\n",
    "cols = current_unnormalized.shape[0]\n",
    "\n",
    "gs = gridspec.GridSpec(no_ens_rows, cols)#, width_ratios=col_width_ratios)\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))#, constrained_layout=True)\n",
    "\n",
    "\n",
    "axes = np.empty((no_ens_rows, cols), dtype=object)\n",
    "for i in range(no_ens_rows):\n",
    "    for j in range(cols):\n",
    "        axes[i,j] = plt.subplot(gs[i,j])\n",
    "\n",
    "\n",
    "place_text(axes[0,0], \"Truth\")\n",
    "place_text(axes[1,0], \"Sample #1\")\n",
    "place_text(axes[2,0], \"Sample #2\")\n",
    "place_text(axes[3,0], \"Sample #3\")\n",
    "place_text(axes[4,0], \"Ensemble Mean\")\n",
    "place_text(axes[5,0], \"Ensemble Std\")\n",
    "\n",
    "for i in range(cols):\n",
    "    \n",
    "\n",
    "    plot_image(axes[0,i], current_unnormalized[i], f't={time_labels[i]}', vmin=min_value, vmax=max_value)\n",
    "    \n",
    "    for j in range(1, 4):\n",
    "        plot_image(axes[j, i], ensembles[j-1, i], vmin=min_value, vmax=max_value)\n",
    "    \n",
    "    plot_image(axes[4,i], ens_mean[i], vmin=min_value, vmax=max_value)\n",
    "    plot_image(axes[5,i], ens_std[i], vmin=0, vmax=ens_std.max())\n",
    "\n",
    "\n",
    "plt.savefig('figures/long_ensemble_plot.pdf', dpi=100, format='pdf', bbox_inches='tight')#, pad_inches=0.1, transparent=True, quality=95, optimize=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = previous_unnormalized.cpu().detach().numpy()[0,0]\n",
    "forecast = ensembles[0,:,0].cpu().detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(4, 4))\n",
    "axes.imshow(forecast[2], cmap=cmap)\n",
    "axes.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figures/direct3.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **State:** Iterative vs Direct Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_kmin = 10\n",
    "t_kmax = 150\n",
    "t_d = 10\n",
    "\n",
    "k_series = t_kmin + t_d * np.arange(0, 1 + (t_kmax-t_kmin)//t_d)\n",
    "val_time_series_dataset = QGDataset(lead_time=k_series, dataset_mode='val', **QG_kwargs)\n",
    "val_time_series_loader = DataLoader(val_time_series_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for previous, current, time_label in (val_time_series_loader):\n",
    "\n",
    "        current = current.to(device).permute(1,0,2,3)\n",
    "        previous = previous.to(device)\n",
    "\n",
    "        current_latent = autoencoder.encoder(current)\n",
    "\n",
    "        time_labels = time_label[0].to(device)\n",
    "        previous_latent = autoencoder.encoder(previous)\n",
    "        \n",
    "        scaling = residual_scaling(time_labels).view(-1, 1, 1, 1)\n",
    "        target_latent =  (current_latent - previous_latent) / scaling\n",
    "        \n",
    "        class_labels = previous_latent.repeat(current.shape[0], 1, 1, 1)\n",
    "\n",
    "        current_unnormalized = current * std_data + mean_data\n",
    "        previous_unnormalized = previous * std_data + mean_data\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ens = 3\n",
    "\n",
    "latents_list = []\n",
    "ensembles_list = []\n",
    "\n",
    "for i in range(n_ens): \n",
    "    latents = torch.randn_like(class_labels[0], device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "    latents_list.append(latents)\n",
    "\n",
    "latents_list = torch.stack(latents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_outs = len(time_labels)\n",
    "\n",
    "ensembles = []\n",
    "ensembles_ar = []\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    for i in range(n_ens):\n",
    "        # Direct  \n",
    "        #latents = torch.randn_like(class_labels[0], device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "        latents = latents_list[i]\n",
    "        predicted_residuals = heun_sampler(model, latents, class_labels, time_labels/max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20)\n",
    "        predicted_latent = previous_latent + predicted_residuals * scaling\n",
    "        predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "        predicted_unnormalized = predicted * std_data + mean_data\n",
    "        ensembles.append(predicted_unnormalized)\n",
    "    \n",
    "    direct_time = time.time() - start_time\n",
    "    # Autoreg\n",
    "    latents = latents_list[:,0]\n",
    "    prev_pred = class_labels[0].repeat(n_ens, 1, 1, 1)\n",
    "    time_label = time_labels[0].repeat(n_ens)\n",
    "    scale = residual_scaling(time_label).view(-1, 1, 1, 1)\n",
    "\n",
    "    for i in range(roll_outs):\n",
    "        predicted_ar_residuals = heun_sampler(model, latents, prev_pred, time_label/max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20)\n",
    "        predicted_ar_latent = prev_pred + predicted_ar_residuals * scale\n",
    "        \n",
    "        predicted_ar = autoencoder.decoder(predicted_ar_latent.to(torch.float32))\n",
    "        \n",
    "        prev_pred = predicted_ar_latent\n",
    "        \n",
    "        predicted_unnormalized_ar = predicted_ar * std_data + mean_data\n",
    "        ensembles_ar.append(predicted_unnormalized_ar)\n",
    "    \n",
    "    iterative_time = time.time() - start_time - direct_time\n",
    "\n",
    "ensembles = torch.stack(ensembles)\n",
    "ensembles_ar = torch.stack(ensembles_ar).permute(1,0,2,3,4)\n",
    "\n",
    "print(f\"Direct sampling time: {direct_time:.2f}s\")\n",
    "print(f\"Iterative sampling time: {iterative_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = len(time_labels)\n",
    "dx = ensembles.shape[3]\n",
    "dy = ensembles.shape[4]\n",
    "\n",
    "truth = current_unnormalized.cpu().detach().numpy().reshape((-1, dx, dy))\n",
    "cond = previous_unnormalized.cpu().detach().numpy().reshape((-1, dx, dy))\n",
    "forecasts_dir = ensembles.cpu().detach().numpy().reshape((n_ens, dt, dx,dy))\n",
    "forecasts_ar = ensembles_ar.cpu().detach().numpy().reshape((n_ens, dt, dx,dy))\n",
    "\n",
    "ens_mean_dir = forecasts_dir.mean(axis=0)\n",
    "ens_std_dir = forecasts_dir.std(axis=0)\n",
    "\n",
    "ens_mean_ar = forecasts_ar.mean(axis=0)\n",
    "ens_std_ar = forecasts_ar.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = 0\n",
    "ti = 2\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(4, 4))\n",
    "#axes.imshow(forecasts_dir[en, ti], cmap=cmap)\n",
    "axes.imshow(forecasts_ar[en, ti], cmap=cmap)\n",
    "#axes.imshow(cond[0], cmap=cmap)\n",
    "axes.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'figures/iterative3.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = 2\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(4, 4))\n",
    "axes.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "for ti in range(len(time_labels)):\n",
    "    #axes.imshow(forecasts_ar[en, ti], cmap=cmap)\n",
    "    axes.imshow(truth[ti], cmap=cmap)\n",
    "    pass\n",
    "    plt.savefig(f'gifs/truth/truth-{ti+1}.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "\n",
    "#axes.imshow(cond[0], cmap=cmap)\n",
    "\n",
    "#plt.savefig(f'gifs/truth/truth-{0}.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = 2\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(4, 4))\n",
    "axes.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "axes.imshow(cond[0], cmap=cmap)\n",
    "\n",
    "#plt.savefig(f'figures/an_dir.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# equivalent to rcParams['animation.html'] = 'html5'\n",
    "rc('animation', html='html5')\n",
    "\n",
    "fig, axes = plt.subplots(3,3, figsize=(10,11), constrained_layout=True)\n",
    "\n",
    "txt_title = fig.suptitle('', va='top')\n",
    "for ax in axes.flatten():\n",
    "    ax.axis('off')\n",
    "\n",
    "title1 = axes[0,0].set_title('')\n",
    "title2 = axes[0,1].set_title('')\n",
    "title3 = axes[0,2].set_title('')\n",
    "\n",
    "images = []\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i == 0:\n",
    "        pass\n",
    "        images.append(ax.imshow(truth[0], cmap=cmap))\n",
    "    elif i == 1:\n",
    "        images.append(ax.imshow(ens_mean_ar[0]))\n",
    "    elif i == 2:\n",
    "        images.append(ax.imshow(ens_mean_dir[0], cmap=cmap))\n",
    "    elif i <=5:\n",
    "        images.append(ax.imshow(forecasts_dir[i-3,0], cmap=cmap))\n",
    "        ax.set_title(f'Direct #{i-2}')\n",
    "    else:\n",
    "        images.append(ax.imshow(forecasts_ar[i-6,0], cmap=cmap))\n",
    "        ax.set_title(f'Iterative #{i-5}')\n",
    "\n",
    "# animation function. This is called sequentially\n",
    "def drawframe(n):\n",
    "    for i, im in enumerate(images):\n",
    "        if i == 0:\n",
    "            pass\n",
    "            im.set_array(truth[n])\n",
    "        elif i == 1:\n",
    "            im.set_array(ens_mean_ar[n])\n",
    "        elif i == 2:\n",
    "            im.set_array(ens_mean_dir[n])\n",
    "        elif i < 6:\n",
    "            im.set_array(forecasts_dir[i-3,n])\n",
    "        else:\n",
    "            im.set_array(forecasts_ar[i-6,n])\n",
    "\n",
    "\n",
    "    txt_title.set_text(f't={time_labels[n].item()}')\n",
    "    title1.set_text('Truth')\n",
    "    title2.set_text('Ensemble Mean Iterative')\n",
    "    title3.set_text('Ensemble Mean Direct')\n",
    "\n",
    "    return images\n",
    "\n",
    "anim = animation.FuncAnimation(fig, drawframe, frames=dt, interval=100)\n",
    "\n",
    "#anim.save('figures/animation.gif', writer='imagemagick', fps=30)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot:** RMSE over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_plot(model, n_ens=1, n_batches=1, selected_loader=val_loader, sampler_fn=heun_sampler):\n",
    "    model.eval()\n",
    "\n",
    "    result = {}\n",
    "    result['rmse_model'] = np.zeros(n_batches*batch_size)\n",
    "    result['rmse_clim'] = np.zeros(n_batches*batch_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for count, (previous, current, time_label) in enumerate(tqdm(selected_loader)):\n",
    "            current = current.to(device)\n",
    "            time_label = time_label.to(device)\n",
    "            if count >= n_batches:\n",
    "                break\n",
    "\n",
    "            predicted_unnormalized = generate_ensemble_from_batch(model, previous, time_label[0], n_ens=n_ens, sampler_fn=sampler_fn)\n",
    "\n",
    "            current_unnormalized = current * std_data + mean_data\n",
    "            previous_unnormalized = previous * std_data + mean_data\n",
    "\n",
    "            #  Note that this is kind of cheating since we are using the validation set to calculate the climatology.\n",
    "            #  More realistic if we have a larger batch size.\n",
    "            #climatology = previous_unnormalized.mean(dim=0, keepdim=True)\n",
    "\n",
    "            ensemble_mean = predicted_unnormalized.mean(dim=0)\n",
    "\n",
    "            rmse_model = calculate_RMSE(ensemble_mean, current_unnormalized)\n",
    "            rmse_clim = calculate_RMSE(climatology, current_unnormalized)\n",
    "\n",
    "            result['rmse_model'][count*batch_size:count*batch_size+rmse_model.size] = rmse_model.flatten()\n",
    "            result['rmse_clim'][count*batch_size:count*batch_size+rmse_model.size] = rmse_clim.flatten()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time = 150\n",
    "batch_size = 16\n",
    "val_dataset = QGDataset(lead_time=lead_time, dataset_mode='val', **QG_kwargs)\n",
    "val_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "n_batches = 1\n",
    "\n",
    "# NWP\n",
    "\n",
    "n_val = 210000\n",
    "nwp_data_path = Path(f'/nobackup/smhid20/users/sm_maran/dpr_data/simulations/QG_samples_LRES_{iterations}_n_{n_val}_k_{lead_time}.npy') if on_remote else Path(f'C:/Users/svart/Desktop/MEX/data/QG_samples_LRES_{iterations}_n_{n_val}_k_{lead_time}.npy')\n",
    "nwp_dataset = NWPDataset(nwp_data_path, n_val=n_val, spacing=spacing, device=device)\n",
    "nwp_loader = DataLoader(nwp_dataset, batch_size=batch_size, shuffle=False)\n",
    "nwp_skill = calculate_nwp_skill(n_batches=n_batches)\n",
    "\n",
    "# Climate and skill\n",
    "climatology = calculate_climatology(train_loader, n_batches=n_batches)\n",
    "\n",
    "n_ens = 10\n",
    "running_mean = 100\n",
    "\n",
    "result = rmse_plot(model, n_ens, n_batches, selected_loader=val_loader, sampler_fn=heun_sampler)\n",
    "\n",
    "rmse_model, rmse_clim = result['rmse_model'], result['rmse_clim']\n",
    "rmse_nwp = nwp_skill[:n_batches*batch_size]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(f'{lead_time} step ahead prediction, {n_ens} ensemble members')\n",
    "plt.plot(uniform_filter1d(rmse_model, size=running_mean), label='Ensemble Mean', color='b')\n",
    "plt.plot(uniform_filter1d(rmse_clim, size=running_mean), label='Climatology', color='r')\n",
    "plt.plot(uniform_filter1d(rmse_nwp, size=running_mean), label='NWP', color='g')\n",
    "plt.ylim(0,11)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('RMSE', fontsize=12)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_density_plot(ensemble_rmses, ensemble_skill):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.hist(ensemble_rmses, bins=100)\n",
    "    plt.axvline(ensemble_skill, color='red', linestyle='--')\n",
    "    plt.xlabel('Ensemble RMSEs')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Density Plot of Ensemble RMSEs')\n",
    "    plt.show()\n",
    "\n",
    "rmse_density_plot(ensemble_rmses, ensemble_skill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot:** Spread vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed k sampling\n",
    "# Way to load a single trajectory. Only uses 1 batch.\n",
    "t_kmin = 10\n",
    "t_kmax = 150\n",
    "t_d = 10\n",
    "k_series = t_kmin + t_d * np.arange(0, 1 + (t_kmax-t_kmin)//t_d)\n",
    "val_time_series_dataset = QGDataset(lead_time=k_series, dataset_mode='val', **QG_kwargs)\n",
    "val_time_series_loader = DataLoader(val_time_series_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "n_batches = 1\n",
    "\n",
    "spread_list = []\n",
    "skill_list = []\n",
    "ratio_list = []\n",
    "\n",
    "for i in tqdm(range(n_batches)):\n",
    "        \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    n_ens = 10\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for previous, current, time_label in (val_time_series_loader):\n",
    "            current = current.to(device).permute(1,0,2,3)\n",
    "            previous = previous.to(device)\n",
    "\n",
    "            current_latent = autoencoder.encoder(current)\n",
    "\n",
    "            time_labels = time_label[0].to(device)\n",
    "            \n",
    "            previous_latent = autoencoder.encoder(previous)\n",
    "            \n",
    "            scaling = residual_scaling(time_labels).view(-1, 1, 1, 1)\n",
    "            target_latent =  (current_latent - previous_latent) / scaling\n",
    "            \n",
    "            class_labels = previous_latent.repeat(current.shape[0], 1, 1, 1)\n",
    "\n",
    "            current_unnormalized = current * std_data + mean_data\n",
    "            previous_unnormalized = previous * std_data + mean_data\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "    ensembles = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(n_ens)):    \n",
    "            latents = torch.randn_like(class_labels[0].unsqueeze(0), device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "\n",
    "            predicted_residuals = heun_sampler(model, latents, class_labels, time_labels/max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20)\n",
    "            predicted_latent = previous_latent + predicted_residuals * scaling\n",
    "\n",
    "            predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "\n",
    "            predicted_unnormalized = predicted * std_data + mean_data\n",
    "\n",
    "            ensembles.append(predicted_unnormalized)\n",
    "\n",
    "    ensembles = torch.stack(ensembles)\n",
    "    ens_mean = ensembles.mean(dim=0)\n",
    "\n",
    "\n",
    "    spreads = []\n",
    "    skills = []\n",
    "\n",
    "    for i in range(len(time_labels)):\n",
    "        truth = current_unnormalized[i]\n",
    "        predicted = ens_mean[i]\n",
    "        ensemble = ensembles[:, i]\n",
    "\n",
    "        skill, spread,_ = calculate_skill_and_spread_score(ensemble, truth)\n",
    "        spreads.append(spread[0])\n",
    "        skills.append(skill[0])\n",
    "    \n",
    "    spread_list.append(spreads)\n",
    "    skill_list.append(skills)\n",
    "    ratio_list.append(np.array(spreads)/np.array(skills))\n",
    "\n",
    "spread_list = np.array(spread_list)\n",
    "skill_list = np.array(skill_list)\n",
    "ratio_list = np.array(ratio_list)\n",
    "time_labels = time_labels.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreads = spread_list.mean(axis=0)\n",
    "skills = skill_list.mean(axis=0)\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.xlabel('Lead time')\n",
    "\n",
    "plt.xticks([0,50,100,150])\n",
    "plt.xlim([-10,160])\n",
    "plt.yticks([0,2,4,6])\n",
    "plt.ylim(0-0.3, 6+0.3)\n",
    "\n",
    "plt.plot(time_labels, uniform_filter1d(spreads, size=1), label='Spread', color='#0000FF')\n",
    "plt.plot(time_labels, uniform_filter1d(skills, size=1), label='Skill', color='#EE82EE')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'figures/skill_spread_{lead_time}_{n_ens}.pdf', dpi=100, format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot:** Rank Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ensembles(n_ens, n_batches, selected_loader=val_loader):\n",
    "    model.eval()\n",
    "\n",
    "    ensembles = []\n",
    "    truths = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for count, (previous, current, time_label) in enumerate(tqdm(selected_loader, total=n_batches)):\n",
    "            if count >= n_batches:\n",
    "                break\n",
    "            current = current.to(device)\n",
    "\n",
    "            predicted_unnormalized = generate_ensemble_from_batch(model, previous, time_label[0], n_ens=n_ens, sampler_fn=heun_sampler)\n",
    "            current_unnormalized = current * std_data + mean_data\n",
    "\n",
    "            ensembles.append(predicted_unnormalized)\n",
    "            truths.append(current_unnormalized)\n",
    "\n",
    "    ensembles = torch.cat(ensembles, dim=1)\n",
    "    truths = torch.cat(truths, dim=0)\n",
    "    return ensembles, truths\n",
    "\n",
    "\n",
    "lead_time = 150\n",
    "batch_size = 16\n",
    "val_dataset = QGDataset(lead_time=lead_time, dataset_mode='val', **QG_kwargs)\n",
    "val_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "n_ens = 1\n",
    "n_batches = 1\n",
    "\n",
    "ensembles, truths = generate_ensembles(n_ens, n_batches, selected_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank Histogram\n",
    "\n",
    "def calculate_rank(predicted, target):\n",
    "    ranks = (target[None, :] < predicted).sum(axis=0)\n",
    "    return ranks\n",
    "\n",
    "def rank_histogram(pixel, ensembles, truths):\n",
    "\n",
    "    pixel_x, pixel_y = pixel\n",
    "    \n",
    "    ensemble = ensembles[:, :, 0, pixel_x, pixel_y]\n",
    "    target = truths[:, 0, pixel_x, pixel_y]\n",
    "\n",
    "    rank = calculate_rank(ensemble, target)\n",
    "\n",
    "    return rank.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New look\n",
    "\n",
    "ranks = np.zeros(n_ens+1)\n",
    "for i in range(0, truths.shape[2]):\n",
    "    for j in range(0, truths.shape[3]):\n",
    "        pixel = (i,j)\n",
    "        rank = rank_histogram(pixel, ensembles, truths)\n",
    "        freq = np.bincount(rank, minlength=n_ens+1)\n",
    "        ranks += freq\n",
    "\n",
    "print(f'{n_ens} members, {n_batches*batch_size} samples')\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.title(f'k={lead_time}')\n",
    "plt.plot(np.linspace(0,1,n_ens+1), ranks*(n_ens+1)/(sum(ranks)), color='black')\n",
    "plt.xlabel('Rank (normalized)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.ylim(-0.1,2.1)\n",
    "plt.yticks([0,0.5,1,1.5,2])\n",
    "plt.xticks([0,0.25,0.5,0.75,1])\n",
    "plt.axhline(1, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.savefig(f'figures/rank_histogram_{lead_time}_{n_ens}_{n_batches*batch_size}.pdf', dpi=100, format='pdf', bbox_inches='tight')#, pad_inches=0.1, transparent=True, quality=95, optimize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel = (np.random.randint(0, truths.shape[2]), np.random.randint(0, truths.shape[3]))\n",
    "print(pixel)\n",
    "#pixel = (1,33)\n",
    "ranks = np.zeros(n_ens+1)\n",
    "rank = rank_histogram(pixel, ensembles, truths)\n",
    "freq = np.bincount(rank, minlength=n_ens+1)\n",
    "ranks += freq\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.title(f'{lead_time} lead time, {n_ens} members, {n_batches*batch_size} samples')\n",
    "plt.bar(np.arange(n_ens+1), ranks/(sum(ranks)), facecolor='white', edgecolor='black')\n",
    "plt.axhline(1/(n_ens+1), color='k', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot:** Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: We can not do the same boxplots as before since we sample at the same time as calculating likelihood\n",
    "And also not evaluate the effect of eps_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_estimate_likelihood(model, n_ens=10, selected_loader = val_loader, sampler_fn=likelihood_sampler, num_steps=20, eps_multiplier=1):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for previous, current, time_label in selected_loader:\n",
    "        previous_unbatched = previous[0].unsqueeze(0).to(device)\n",
    "        current_unbatched = current[0].unsqueeze(0).to(device)\n",
    "        break\n",
    "\n",
    "    with torch.no_grad():\n",
    "        previous_latent = autoencoder.encoder(previous_unbatched)\n",
    "\n",
    "        class_labels = previous_latent.repeat(n_ens, 1, 1, 1)\n",
    "        latents = torch.randn_like(class_labels, device=device)\n",
    "\n",
    "        current_unnormalized = current_unbatched * std_data + mean_data\n",
    "        previous_unnormalized = previous_unbatched * std_data + mean_data\n",
    "\n",
    "    predicted_unnormalized_ensemble = torch.zeros((n_ens, 1, previous.size(1), previous.size(2), previous.size(3)), device=device)\n",
    "    likelihood_ensemble = np.zeros(n_ens)\n",
    "    rmse_ensemble = np.zeros(n_ens)\n",
    "    mae_ensemble = np.zeros(n_ens)\n",
    "\n",
    "    for j in tqdm(range(n_ens)):\n",
    "        with torch.no_grad():\n",
    "            latent = latents[j].unsqueeze(0)\n",
    "            class_label = class_labels[j].unsqueeze(0)\n",
    "            time_labels = time_label[0].repeat(n_ens).to(device)\n",
    "\n",
    "            predicted_residuals, likelihood  = sampler_fn(model, \n",
    "                                    latent, \n",
    "                                    class_label,\n",
    "                                    time_labels / max_lead_time,\n",
    "                                    eps_multiplier=eps_multiplier,\n",
    "                                    num_steps=num_steps,\n",
    "                                    sigma_max=80, sigma_min=0.03, rho=7, \n",
    "                                    S_churn=2.5, S_min=0.75, S_max=80, S_noise=1.05)\n",
    "            \n",
    "            predicted_latent = previous_latent + predicted_residuals * residual_scaling(time_labels)\n",
    "            \n",
    "            predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "\n",
    "            predicted_unnormalized = predicted * std_data + mean_data\n",
    "            predicted_unnormalized_ensemble[j] = predicted_unnormalized\n",
    "            likelihood_ensemble[j] = likelihood.item()\n",
    "\n",
    "            # ----\n",
    "            ensemble_rmse = calculate_RMSE(predicted_unnormalized, current_unnormalized).flatten()\n",
    "            ensemble_mae = calculate_MAE(predicted_unnormalized, current_unnormalized).flatten()\n",
    "            \n",
    "            rmse_ensemble[j] = ensemble_rmse.item()\n",
    "            mae_ensemble[j] = ensemble_mae.item()\n",
    "            print(f\"Likelihood {j}: {likelihood.item():.0f}, RMSE {j}: {rmse_ensemble[j]:.2f}, MAE {j}: {mae_ensemble[j]:.2f}\")\n",
    "        \n",
    "    return predicted_unnormalized_ensemble, current_unnormalized, likelihood_ensemble, rmse_ensemble, mae_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ens = 1\n",
    "eps_multiplier = 1\n",
    "num_steps = 20\n",
    "\n",
    "predicted_unnormalized_ensemble, current_unnormalized, likelihood_ensemble, rmse_ensemble, mae_ensemble = generate_and_estimate_likelihood(model, n_ens=n_ens, selected_loader = val_loader, sampler_fn=likelihood_sampler, num_steps=num_steps, eps_multiplier=eps_multiplier)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.xlabel('MAE')\n",
    "plt.ylabel('Likelihood')\n",
    "plt.title('Likelihood vs RMSE')\n",
    "plt.plot(rmse_ensemble, -likelihood_ensemble, marker='o', linestyle='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot:** Frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_kmin = 10\n",
    "t_kmax = 150\n",
    "t_d = 10\n",
    "\n",
    "k_series = t_kmin + t_d * np.arange(0, 1 + (t_kmax-t_kmin)//t_d)\n",
    "val_time_series_dataset = QGDataset(lead_time=k_series, dataset_mode='val', **QG_kwargs)\n",
    "val_time_series_loader = DataLoader(val_time_series_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for previous, current, time_label in (val_time_series_loader):\n",
    "\n",
    "        current = current.to(device).permute(1,0,2,3)\n",
    "        previous = previous.to(device)\n",
    "\n",
    "        current_latent = autoencoder.encoder(current)\n",
    "\n",
    "        time_labels = time_label[0].to(device)\n",
    "        previous_latent = autoencoder.encoder(previous)\n",
    "        \n",
    "        scaling = residual_scaling(time_labels).view(-1, 1, 1, 1)\n",
    "        target_latent =  (current_latent - previous_latent) / scaling\n",
    "        \n",
    "        class_labels = previous_latent.repeat(current.shape[0], 1, 1, 1)\n",
    "\n",
    "        current_unnormalized = current * std_data + mean_data\n",
    "        previous_unnormalized = previous * std_data + mean_data\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ens = 3\n",
    "\n",
    "latents_list = []\n",
    "ensembles_list = []\n",
    "\n",
    "for i in range(n_ens): \n",
    "    latents = torch.randn_like(class_labels[0], device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "    latents_list.append(latents)\n",
    "\n",
    "latents_list = torch.stack(latents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_outs = len(time_labels)\n",
    "\n",
    "ensembles = []\n",
    "ensembles_ar = []\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    for i in range(n_ens):\n",
    "        # Direct  \n",
    "        #latents = torch.randn_like(class_labels[0], device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "        latents = latents_list[i]\n",
    "        predicted_residuals = heun_sampler(model, latents, class_labels, time_labels/max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20)\n",
    "        predicted_latent = previous_latent + predicted_residuals * scaling\n",
    "        predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "        predicted_unnormalized = predicted * std_data + mean_data\n",
    "        ensembles.append(predicted_unnormalized)\n",
    "    \n",
    "    direct_time = time.time() - start_time\n",
    "    # Autoreg\n",
    "    latents = latents_list[:,0]\n",
    "    prev_pred = class_labels[0].repeat(n_ens, 1, 1, 1)\n",
    "    time_label = time_labels[0].repeat(n_ens)\n",
    "    scale = residual_scaling(time_label).view(-1, 1, 1, 1)\n",
    "\n",
    "    for i in range(roll_outs):\n",
    "        predicted_ar_residuals = heun_sampler(model, latents, prev_pred, time_label/max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20)\n",
    "        predicted_ar_latent = prev_pred + predicted_ar_residuals * scale\n",
    "        \n",
    "        predicted_ar = autoencoder.decoder(predicted_ar_latent.to(torch.float32))\n",
    "        \n",
    "        prev_pred = predicted_ar_latent\n",
    "        \n",
    "        predicted_unnormalized_ar = predicted_ar * std_data + mean_data\n",
    "        ensembles_ar.append(predicted_unnormalized_ar)\n",
    "    \n",
    "    iterative_time = time.time() - start_time - direct_time\n",
    "\n",
    "ensembles = torch.stack(ensembles)\n",
    "ensembles_ar = torch.stack(ensembles_ar).permute(1,0,2,3,4)\n",
    "\n",
    "print(f\"Direct sampling time: {direct_time:.2f}s\")\n",
    "print(f\"Iterative sampling time: {iterative_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = len(time_labels)\n",
    "dx = ensembles.shape[3]\n",
    "dy = ensembles.shape[4]\n",
    "\n",
    "truth = current_unnormalized.cpu().detach().numpy().reshape((-1, dx, dy))\n",
    "forecasts_dir = ensembles.cpu().detach().numpy().reshape((n_ens, dt, dx,dy))\n",
    "forecasts_ar = ensembles_ar.cpu().detach().numpy().reshape((n_ens, dt, dx,dy))\n",
    "\n",
    "ens_mean_dir = forecasts_dir.mean(axis=0)\n",
    "ens_std_dir = forecasts_dir.std(axis=0)\n",
    "\n",
    "ens_mean_ar = forecasts_ar.mean(axis=0)\n",
    "ens_std_ar = forecasts_ar.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft2, ifft2, fftshift\n",
    "lead_t = 14\n",
    "ens = 1\n",
    "forecast_dir_t = forecasts_dir[ens, lead_t]\n",
    "forecast_ar_t = forecasts_ar[ens, lead_t]\n",
    "truth_t = truth[lead_t]\n",
    "\n",
    "fft_forecast_dir = fftshift(fft2(forecast_dir_t))\n",
    "fft_forecast_ar = fftshift(fft2(forecast_ar_t))\n",
    "fft_truth = fftshift(fft2(truth_t))\n",
    "\n",
    "mag_forecast_dir = np.abs(fft_forecast_dir)\n",
    "mag_forecast_ar = np.abs(fft_forecast_ar)\n",
    "mag_truth = np.abs(fft_truth)\n",
    "\n",
    "# Plot the magnitude of the FFT for each image\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.suptitle('Magnitude of the 2D FFT', fontsize=16)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(np.log1p(mag_truth), cmap='gray')\n",
    "plt.title('Truth')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(np.log1p(mag_forecast_dir), cmap='gray')\n",
    "plt.title('Direct')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(np.log1p(mag_forecast_ar), cmap='gray')\n",
    "plt.title('Iterative')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plot:** Temporal consistency evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed k sampling\n",
    "# Way to load a single trajectory. Only uses 1 batch.\n",
    "t_kmin = 1\n",
    "t_kmax = 150\n",
    "t_d = 1\n",
    "k_series = t_kmin + t_d * np.arange(0, 1 + (t_kmax-t_kmin)//t_d)\n",
    "val_time_series_dataset = QGDataset(lead_time=k_series, dataset_mode='val', **QG_kwargs)\n",
    "val_time_series_loader = DataLoader(val_time_series_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "n_batches = 1\n",
    "\n",
    "spread_list = []\n",
    "skill_list = []\n",
    "ratio_list = []\n",
    "\n",
    "for i in tqdm(range(n_batches)):\n",
    "        \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    n_ens = 100\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for previous, current, time_label in (val_time_series_loader):\n",
    "            current = current.to(device).permute(1,0,2,3)\n",
    "            previous = previous.to(device)\n",
    "\n",
    "            current_latent = autoencoder.encoder(current)\n",
    "\n",
    "            time_labels = time_label[0].to(device)\n",
    "            \n",
    "            previous_latent = autoencoder.encoder(previous)\n",
    "            \n",
    "            scaling = residual_scaling(time_labels).view(-1, 1, 1, 1)\n",
    "            target_latent =  (current_latent - previous_latent) / scaling\n",
    "            \n",
    "            class_labels = previous_latent.repeat(current.shape[0], 1, 1, 1)\n",
    "\n",
    "            current_unnormalized = current * std_data + mean_data\n",
    "            previous_unnormalized = previous * std_data + mean_data\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "    ensembles = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(n_ens)):    \n",
    "            latents = torch.randn_like(class_labels[0].unsqueeze(0), device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "\n",
    "            predicted_residuals = heun_sampler(model, latents, class_labels, time_labels/max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20)\n",
    "            predicted_latent = previous_latent + predicted_residuals * scaling\n",
    "\n",
    "            predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "\n",
    "            predicted_unnormalized = predicted * std_data + mean_data\n",
    "\n",
    "            ensembles.append(predicted_unnormalized)\n",
    "\n",
    "    ensembles = torch.stack(ensembles)\n",
    "    ens_mean = ensembles.mean(dim=0)\n",
    "\n",
    "\n",
    "    spreads = []\n",
    "    skills = []\n",
    "\n",
    "    for i in range(len(time_labels)):\n",
    "        truth = current_unnormalized[i]\n",
    "        predicted = ens_mean[i]\n",
    "        ensemble = ensembles[:, i]\n",
    "\n",
    "        skill, spread,_ = calculate_skill_and_spread_score(ensemble, truth)\n",
    "        spreads.append(spread[0])\n",
    "        skills.append(skill[0])\n",
    "    \n",
    "    spread_list.append(spreads)\n",
    "    skill_list.append(skills)\n",
    "    ratio_list.append(np.array(spreads)/np.array(skills))\n",
    "\n",
    "spread_list = np.array(spread_list)\n",
    "skill_list = np.array(skill_list)\n",
    "ratio_list = np.array(ratio_list)\n",
    "time_labels = time_labels.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_latent = ((ensembles[1:, 1:] - ensembles[1:, :-1])**2).mean(dim=(2,3,4)).sqrt().cpu().permute(1,0)\n",
    "different_latent = ((ensembles[1:, 1:] - ensembles[:-1, :-1])**2).mean(dim=(2,3,4)).sqrt().cpu().permute(1,0)\n",
    "\n",
    "print(same_latent.mean(), different_latent.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "\n",
    "plt.xlabel('Lead time')\n",
    "plt.ylabel('RMS($X_{t+1}$, $X_t$)')\n",
    "\n",
    "plt.xticks([0,50,100,150])\n",
    "plt.xlim([-10,160])\n",
    "#plt.yticks([0,2,4,6])\n",
    "#plt.ylim(0-0.3, 6+0.3)\n",
    "\n",
    "#plt.plot(different_latent, label = \"Uncorrelated\", color='#EE82EE')\n",
    "plt.plot(same_latent, label = \"DEFfusion\", color='#0000FF')\n",
    "\n",
    "#plt.legend(loc='upper left')\n",
    "\n",
    "plt.savefig(f'figures/temporal_coherence.pdf', dpi=100, format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Animation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Animation:** Direct forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_kmin = 1\n",
    "t_kmax = 36\n",
    "t_d = 1\n",
    "\n",
    "k_series = t_kmin + t_d * np.arange(0, 1 + (t_kmax-t_kmin)//t_d)\n",
    "val_time_series_dataset = QGDataset(lead_time=k_series, dataset_mode='val', **WB_kwargs)\n",
    "val_time_series_loader = DataLoader(val_time_series_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for previous, current, time_label in (val_time_series_loader):\n",
    "\n",
    "        current = current.to(device).permute(1,0,2,3)\n",
    "        previous = previous.to(device)\n",
    "\n",
    "        current_latent = autoencoder.encoder(current)\n",
    "\n",
    "        time_labels = time_label[0].to(device)\n",
    "        previous_latent = autoencoder.encoder(previous)\n",
    "        \n",
    "        scaling = residual_scaling(time_labels).view(-1, 1, 1, 1)\n",
    "        target_latent =  (current_latent - previous_latent) / scaling\n",
    "        \n",
    "        class_labels = previous_latent.repeat(current.shape[0], 1, 1, 1)\n",
    "\n",
    "        current_unnormalized = current * std_data + mean_data\n",
    "        previous_unnormalized = previous * std_data + mean_data\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ens = 10\n",
    "\n",
    "latents_list = []\n",
    "ensembles_list = []\n",
    "\n",
    "for i in range(n_ens): \n",
    "    latents = torch.randn_like(class_labels[0], device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "    latents_list.append(latents)\n",
    "\n",
    "latents_list = torch.stack(latents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_outs = len(time_labels)\n",
    "\n",
    "ensembles = []\n",
    "ensembles_ar = []\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i in range(n_ens):\n",
    "        latents = latents_list[i]\n",
    "        predicted_residuals = heun_sampler(model, latents, class_labels, time_labels/max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20)\n",
    "        predicted_latent = previous_latent + predicted_residuals * scaling\n",
    "        predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "        predicted_unnormalized = predicted * std_data + mean_data\n",
    "        ensembles.append(predicted_unnormalized)\n",
    "\n",
    "ensembles = torch.stack(ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = len(time_labels)\n",
    "dx = ensembles.shape[3]\n",
    "dy = ensembles.shape[4]\n",
    "\n",
    "truth = current_unnormalized.cpu().detach().numpy().reshape((-1, dx, dy))\n",
    "forecasts = ensembles.cpu().detach().numpy().reshape((n_ens, dt, dx,dy))\n",
    "\n",
    "ens_mean = forecasts.mean(axis=0)\n",
    "ens_std = forecasts.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# equivalent to rcParams['animation.html'] = 'html5'\n",
    "rc('animation', html='html5')\n",
    "\n",
    "fig, axes = plt.subplots(3,3, figsize=(10,11), constrained_layout=True)\n",
    "\n",
    "txt_title = fig.suptitle('', va='top')\n",
    "for ax in axes.flatten():\n",
    "    ax.axis('off')\n",
    "\n",
    "title1 = axes[0,0].set_title('')\n",
    "title2 = axes[0,1].set_title('')\n",
    "title3 = axes[0,2].set_title('')\n",
    "\n",
    "images = []\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i == 0:\n",
    "        pass\n",
    "        images.append(ax.imshow(truth[0]))\n",
    "    elif i == 1:\n",
    "        images.append(ax.imshow(ens_mean[0], cmap=cmap))\n",
    "    elif i == 2:\n",
    "        images.append(ax.imshow(ens_std[0], cmap=cmap, vmin=0, vmax=ens_std.max()))\n",
    "    else:\n",
    "        images.append(ax.imshow(forecasts[i-3,0], cmap=cmap))\n",
    "        ax.set_title(f'Sample #{i-2}')\n",
    "\n",
    "# animation function. This is called sequentially\n",
    "def drawframe(n):\n",
    "    for i, im in enumerate(images):\n",
    "        if i == 0:\n",
    "            im.set_array(truth[n])\n",
    "        elif i == 1:\n",
    "            im.set_array(ens_mean[n])\n",
    "        elif i == 2:\n",
    "            im.set_array(ens_std[n])\n",
    "        else:\n",
    "            im.set_array(forecasts[i-3,n])\n",
    "\n",
    "    txt_title.set_text(f't={time_labels[n].item()}')\n",
    "    title1.set_text('Truth')\n",
    "    title2.set_text('Ensemble mean')\n",
    "    title3.set_text('Ensemble std')\n",
    "\n",
    "    return images\n",
    "\n",
    "anim = animation.FuncAnimation(fig, drawframe, frames=dt, interval=80)\n",
    "\n",
    "anim.save('figures/animation.gif', writer='imagemagick', fps=12)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Animation:** Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_kmin = 1\n",
    "t_kmax = 1500\n",
    "t_d = 10\n",
    "\n",
    "k_series = t_kmin + t_d * np.arange(0, 1 + (t_kmax-t_kmin)//t_d)\n",
    "val_time_series_dataset = QGDataset(lead_time=k_series, dataset_mode='val', **QG_kwargs)\n",
    "val_time_series_loader = DataLoader(val_time_series_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for previous, current, time_label in (val_time_series_loader):\n",
    "\n",
    "        current = current.to(device).permute(1,0,2,3)\n",
    "\n",
    "        time_labels = time_label[0].to(device)\n",
    "        \n",
    "        current_unnormalized = current * std_data + mean_data\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = len(time_labels)\n",
    "dx = current_unnormalized.shape[2]\n",
    "dy = current_unnormalized.shape[3]\n",
    "\n",
    "truth = current_unnormalized.cpu().detach().numpy().reshape((-1, dx, dy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(dt):\n",
    "    plt.imshow(truth[i], cmap=cmap)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'gifs/frame_{i+1}.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Animation:** Iterative vs Direct Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_kmin = 10\n",
    "t_kmax = 150\n",
    "t_d = 10\n",
    "\n",
    "k_series = t_kmin + t_d * np.arange(0, 1 + (t_kmax-t_kmin)//t_d)\n",
    "val_time_series_dataset = QGDataset(lead_time=k_series, dataset_mode='val', **QG_kwargs)\n",
    "val_time_series_loader = DataLoader(val_time_series_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for previous, current, time_label in (val_time_series_loader):\n",
    "\n",
    "        current = current.to(device).permute(1,0,2,3)\n",
    "        previous = previous.to(device)\n",
    "\n",
    "        current_latent = autoencoder.encoder(current)\n",
    "\n",
    "        time_labels = time_label[0].to(device)\n",
    "        previous_latent = autoencoder.encoder(previous)\n",
    "        \n",
    "        scaling = residual_scaling(time_labels).view(-1, 1, 1, 1)\n",
    "        target_latent =  (current_latent - previous_latent) / scaling\n",
    "        \n",
    "        class_labels = previous_latent.repeat(current.shape[0], 1, 1, 1)\n",
    "\n",
    "        current_unnormalized = current * std_data + mean_data\n",
    "        previous_unnormalized = previous * std_data + mean_data\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ens = 15\n",
    "\n",
    "latents_list = []\n",
    "ensembles_list = []\n",
    "\n",
    "for i in range(n_ens): \n",
    "    latents = torch.randn_like(class_labels[0], device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "    latents_list.append(latents)\n",
    "\n",
    "latents_list = torch.stack(latents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_outs = len(time_labels)\n",
    "\n",
    "ensembles = []\n",
    "ensembles_ar = []\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    for i in range(n_ens):\n",
    "        # Direct  \n",
    "        #latents = torch.randn_like(class_labels[0], device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "        latents = latents_list[i]\n",
    "        predicted_residuals = heun_sampler(model, latents, class_labels, time_labels/max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20)\n",
    "        predicted_latent = previous_latent + predicted_residuals * scaling\n",
    "        predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "        predicted_unnormalized = predicted * std_data + mean_data\n",
    "        ensembles.append(predicted_unnormalized)\n",
    "    \n",
    "    direct_time = time.time() - start_time\n",
    "    # Autoreg\n",
    "    latents = latents_list[:,0]\n",
    "    prev_pred = class_labels[0].repeat(n_ens, 1, 1, 1)\n",
    "    time_label = time_labels[0].repeat(n_ens)\n",
    "    scale = residual_scaling(time_label).view(-1, 1, 1, 1)\n",
    "\n",
    "    for i in range(roll_outs):\n",
    "        predicted_ar_residuals = heun_sampler(model, latents, prev_pred, time_label/max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20)\n",
    "        predicted_ar_latent = prev_pred + predicted_ar_residuals * scale\n",
    "        \n",
    "        predicted_ar = autoencoder.decoder(predicted_ar_latent.to(torch.float32))\n",
    "        \n",
    "        prev_pred = predicted_ar_latent\n",
    "        \n",
    "        predicted_unnormalized_ar = predicted_ar * std_data + mean_data\n",
    "        ensembles_ar.append(predicted_unnormalized_ar)\n",
    "    \n",
    "    iterative_time = time.time() - start_time - direct_time\n",
    "\n",
    "ensembles = torch.stack(ensembles)\n",
    "ensembles_ar = torch.stack(ensembles_ar).permute(1,0,2,3,4)\n",
    "\n",
    "print(f\"Direct sampling time: {direct_time:.2f}s\")\n",
    "print(f\"Iterative sampling time: {iterative_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = len(time_labels)\n",
    "dx = ensembles.shape[3]\n",
    "dy = ensembles.shape[4]\n",
    "\n",
    "truth = current_unnormalized.cpu().detach().numpy().reshape((-1, dx, dy))\n",
    "forecasts_dir = ensembles.cpu().detach().numpy().reshape((n_ens, dt, dx,dy))\n",
    "forecasts_ar = ensembles_ar.cpu().detach().numpy().reshape((n_ens, dt, dx,dy))\n",
    "\n",
    "ens_mean_dir = forecasts_dir.mean(axis=0)\n",
    "ens_std_dir = forecasts_dir.std(axis=0)\n",
    "\n",
    "ens_mean_ar = forecasts_ar.mean(axis=0)\n",
    "ens_std_ar = forecasts_ar.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# equivalent to rcParams['animation.html'] = 'html5'\n",
    "rc('animation', html='html5')\n",
    "\n",
    "fig, axes = plt.subplots(3,3, figsize=(10,11), constrained_layout=True)\n",
    "\n",
    "txt_title = fig.suptitle('', va='top')\n",
    "for ax in axes.flatten():\n",
    "    ax.axis('off')\n",
    "\n",
    "title1 = axes[0,0].set_title('')\n",
    "title2 = axes[0,1].set_title('')\n",
    "title3 = axes[0,2].set_title('')\n",
    "\n",
    "images = []\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i == 0:\n",
    "        pass\n",
    "        images.append(ax.imshow(truth[0], cmap=cmap))\n",
    "    elif i == 1:\n",
    "        images.append(ax.imshow(ens_mean_ar[0]))\n",
    "    elif i == 2:\n",
    "        images.append(ax.imshow(ens_mean_dir[0], cmap=cmap))\n",
    "    elif i <=5:\n",
    "        images.append(ax.imshow(forecasts_dir[i-3,0], cmap=cmap))\n",
    "        ax.set_title(f'Direct #{i-2}')\n",
    "    else:\n",
    "        images.append(ax.imshow(forecasts_ar[i-6,0], cmap=cmap))\n",
    "        ax.set_title(f'Iterative #{i-5}')\n",
    "\n",
    "# animation function. This is called sequentially\n",
    "def drawframe(n):\n",
    "    for i, im in enumerate(images):\n",
    "        if i == 0:\n",
    "            pass\n",
    "            im.set_array(truth[n])\n",
    "        elif i == 1:\n",
    "            im.set_array(ens_mean_ar[n])\n",
    "        elif i == 2:\n",
    "            im.set_array(ens_mean_dir[n])\n",
    "        elif i < 6:\n",
    "            im.set_array(forecasts_dir[i-3,n])\n",
    "        else:\n",
    "            im.set_array(forecasts_ar[i-6,n])\n",
    "\n",
    "\n",
    "    txt_title.set_text(f't={time_labels[n].item()}')\n",
    "    title1.set_text('Truth')\n",
    "    title2.set_text('Ensemble Mean Iterative')\n",
    "    title3.set_text('Ensemble Mean Direct')\n",
    "\n",
    "    return images\n",
    "\n",
    "anim = animation.FuncAnimation(fig, drawframe, frames=dt, interval=100)\n",
    "\n",
    "#anim.save('figures/animation.gif', writer='imagemagick', fps=30)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Animation:** Interpolation between latent states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_kmin = 1\n",
    "t_kmax = 150\n",
    "t_d = 1\n",
    "\n",
    "k_series = t_kmin + t_d * np.arange(0, 1 + (t_kmax-t_kmin)//t_d)\n",
    "val_time_series_dataset = QGDataset(lead_time=k_series, dataset_mode='val', **QG_kwargs)\n",
    "val_time_series_loader = DataLoader(val_time_series_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for previous, current, time_label in (val_time_series_loader):\n",
    "\n",
    "        current = current.to(device).permute(1,0,2,3)\n",
    "        previous = previous.to(device)\n",
    "\n",
    "        current_latent = autoencoder.encoder(current)\n",
    "\n",
    "        time_labels = time_label[0].to(device)\n",
    "        previous_latent = autoencoder.encoder(previous)\n",
    "        \n",
    "        scaling = residual_scaling(time_labels).view(-1, 1, 1, 1)\n",
    "        target_latent =  (current_latent - previous_latent) / scaling\n",
    "        \n",
    "        class_labels = previous_latent.repeat(current.shape[0], 1, 1, 1)\n",
    "\n",
    "        current_unnormalized = current * std_data + mean_data\n",
    "        previous_unnormalized = previous * std_data + mean_data\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ens = 6\n",
    "\n",
    "latents1 = torch.randn_like(class_labels[0], device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "latents2 = torch.randn_like(class_labels[0], device=device).repeat(class_labels.shape[0], 1, 1, 1)\n",
    "\n",
    "alphas = np.linspace(0, 1, n_ens)\n",
    "\n",
    "def interpolate_latents(alpha):\n",
    "    return np.sqrt(1-alpha)*latents1 + np.sqrt(alpha)*latents2\n",
    "\n",
    "latents_list = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    latents_list.append(interpolate_latents(alpha))\n",
    "\n",
    "latents_list = torch.stack(latents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_outs = len(time_labels)\n",
    "\n",
    "ensembles = []\n",
    "ensembles_ar = []\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i in range(n_ens):\n",
    "        latents = latents_list[i]\n",
    "        predicted_residuals = heun_sampler(model, latents, class_labels, time_labels/max_lead_time, sigma_max=80, sigma_min=0.03, rho=7, num_steps=20)\n",
    "        predicted_latent = previous_latent + predicted_residuals * scaling\n",
    "        predicted = autoencoder.decoder(predicted_latent.to(torch.float32))\n",
    "        predicted_unnormalized = predicted * std_data + mean_data\n",
    "        ensembles.append(predicted_unnormalized)\n",
    "\n",
    "ensembles = torch.stack(ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = len(time_labels)\n",
    "dx = ensembles.shape[3]\n",
    "dy = ensembles.shape[4]\n",
    "\n",
    "truth = current_unnormalized.cpu().detach().numpy().reshape((-1, dx, dy))\n",
    "forecasts = ensembles.cpu().detach().numpy().reshape((n_ens, dt, dx,dy))\n",
    "\n",
    "ens_mean = forecasts.mean(axis=0)\n",
    "ens_std = forecasts.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# equivalent to rcParams['animation.html'] = 'html5'\n",
    "rc('animation', html='html5')\n",
    "\n",
    "fig, axes = plt.subplots(3,3, figsize=(10,11), constrained_layout=True)\n",
    "\n",
    "txt_title = fig.suptitle('', va='top')\n",
    "for ax in axes.flatten():\n",
    "    ax.axis('off')\n",
    "\n",
    "title1 = axes[0,0].set_title('')\n",
    "title2 = axes[0,1].set_title('')\n",
    "title3 = axes[0,2].set_title('')\n",
    "\n",
    "images = []\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i == 0:\n",
    "        pass\n",
    "        images.append(ax.imshow(truth[0], cmap=cmap))\n",
    "    elif i == 1:\n",
    "        images.append(ax.imshow(ens_mean[0], cmap=cmap))\n",
    "    elif i == 2:\n",
    "        images.append(ax.imshow(ens_std[0], cmap=cmap, vmin=0, vmax=ens_std.max()))\n",
    "    else:\n",
    "        images.append(ax.imshow(forecasts[i-3,0], cmap=cmap))\n",
    "        ax.set_title(f'alpha = {alphas[i-3]}')\n",
    "\n",
    "# animation function. This is called sequentially\n",
    "def drawframe(n):\n",
    "    for i, im in enumerate(images):\n",
    "        if i == 0:\n",
    "            im.set_array(truth[n])\n",
    "        elif i == 1:\n",
    "            im.set_array(ens_mean[n])\n",
    "        elif i == 2:\n",
    "            im.set_array(ens_std[n])\n",
    "        else:\n",
    "            im.set_array(forecasts[i-3,n])\n",
    "\n",
    "    txt_title.set_text(f't={time_labels[n].item()}')\n",
    "    title1.set_text('Truth')\n",
    "    title2.set_text('Ensemble mean')\n",
    "    title3.set_text('Ensemble std')\n",
    "\n",
    "    return images\n",
    "\n",
    "anim = animation.FuncAnimation(fig, drawframe, frames=dt, interval=50)\n",
    "\n",
    "#anim.save('figures/animation.gif', writer='imagemagick', fps=30)\n",
    "HTML(anim.to_html5_video())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MEX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
